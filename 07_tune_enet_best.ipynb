{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1725cd6d-6c24-4239-b641-0ff547bf5595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "from datetime import datetime as dt\n",
    "import logging\n",
    "\n",
    "import ray\n",
    "import torch\n",
    "from ray import train, tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from torchvision import transforms\n",
    "\n",
    "from engine import (load_enet_best, get_loss_optimizer, create_writer, pretty_json, val_step, train_step)\n",
    "from load_data_functions import create_cv_datasets, create_dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65aa5e35-fa44-405a-b588-95db2bddbb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = os.getcwd()\n",
    "\n",
    "def tune_enet(config: Dict[str, any], start_time_tuning: str):\n",
    "    \"\"\"\n",
    "    Tune the pretrained EfficientNet model based on the given hyperparameter configuration and\n",
    "    log the results using ray train.report and Tensorboard.\n",
    "\n",
    "    :param config:  Dictionary containing hyperparameters for tuning.\n",
    "        - \"bs\" (int): Batch size.\n",
    "        - \"do\" (float): Dropout probability for the dropout layer.\n",
    "        - \"loss_fn\" (str): Name of the loss function. \n",
    "        - \"lr\" (float): Learning rate.\n",
    "        - \"aug\" (bool): Whether to apply data augmentation to increase the training set size.\n",
    "    :param start_time_tuning: Start time of the tuning run for logging purposes.\n",
    "    \"\"\"\n",
    "    # Extract hyperparameters from the config\n",
    "    batch_size = config[\"bs\"]\n",
    "    dropout_p = config[\"do\"]\n",
    "    loss_fn_str = config[\"loss_fn\"]\n",
    "    learning_rate = config[\"lr\"]\n",
    "    augmentation = config[\"aug\"]\n",
    "\n",
    "    # fixed parameters and other variables\n",
    "    split_path = Path(project_path) / \"data/train_test_split\"\n",
    "    fold_list = [split_path / f\"fold_{i}\" for i in range(1, 6)]\n",
    "    fold_num = 5\n",
    "    used_fold = \"fold_1\"\n",
    "    img_size = 224\n",
    "    model_name = \"pretrained_enet\"\n",
    "    optimizer_str = \"Adam\"\n",
    "    num_epochs = 20\n",
    "    train_percentage = 1.0\n",
    "\n",
    "    # setup device agnostic code\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "\n",
    "    # load model\n",
    "    model = load_enet_best(device, dropout=dropout_p, project_path=project_path)\n",
    "    model.to(device)\n",
    "\n",
    "    # get loss function and optimizer\n",
    "    loss_fn, optimizer = get_loss_optimizer(loss_fn_str, optimizer_str, model, learning_rate)\n",
    "\n",
    "    # define data transforms\n",
    "    data_transforms = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    augment_transform = transforms.Compose([\n",
    "        transforms.Resize(size=(img_size, img_size)),  # resize the images\n",
    "        # randomly add Gaussian blur\n",
    "        transforms.RandomApply([transforms.GaussianBlur(kernel_size=3)], p=0.7),\n",
    "        # randomly perform a horizontal flip\n",
    "        transforms.RandomHorizontalFlip(p=0.7),\n",
    "        # turn the images into a torch.Tensor\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # create training and validation datasets\n",
    "    datasets = create_cv_datasets(fold_list, data_transforms, select_one=False,\n",
    "                                  train_percentage=train_percentage,\n",
    "                                  augmentation=augmentation, augment_transform=augment_transform)\n",
    "    train_data = datasets[used_fold][\"train\"]\n",
    "    validation_data = datasets[used_fold][\"validation\"]\n",
    "    print(f\"Size of the training set: {len(train_data)}\")\n",
    "    print(f\"Size of the validation set: {len(validation_data)}\")\n",
    "    train_loader, val_loader = create_dataloaders(train_data, validation_data, device, batch_size)\n",
    "\n",
    "    # create a writer to track training results\n",
    "    writer = create_writer(f\"hp_tuning\", model_name, f\"{used_fold}_start_{start_time_tuning}\", project_path)\n",
    "\n",
    "    # track hyperparameters and other relevant information\n",
    "    info = {\n",
    "        \"model_name\": model_name,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"dropout_p\": dropout_p,\n",
    "        \"loss_fn_str\": loss_fn_str,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"augmentation\": augmentation,\n",
    "        \"split_path\": str(split_path),\n",
    "        \"fold_list\": [str(fold) for fold in fold_list],\n",
    "        \"validation_fold\": used_fold,\n",
    "        \"fold_num\": fold_num,\n",
    "        \"img_size\": img_size,\n",
    "        \"num_epochs\": num_epochs,\n",
    "        \"optimizer_str\": optimizer_str,\n",
    "        \"percentage\": train_percentage,\n",
    "        \"cross_validation\": False\n",
    "    }\n",
    "\n",
    "    writer.add_text(\"Miscellaneous\", pretty_json(info))\n",
    "\n",
    "    # train the model\n",
    "    fold_train_cccs = []\n",
    "    fold_train_pccs = []\n",
    "    fold_train_loss = []\n",
    "    fold_val_cccs = []\n",
    "    fold_val_pccs = []\n",
    "    fold_val_loss = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_ccc, train_pcc = train_step(model=model,\n",
    "                                                      dataloader=train_loader,\n",
    "                                                      loss_fn=loss_fn,\n",
    "                                                      optimizer=optimizer,\n",
    "                                                      device=device)\n",
    "\n",
    "        val_loss, val_ccc, val_pcc = val_step(model=model,\n",
    "                                              dataloader=val_loader,\n",
    "                                              loss_fn=loss_fn,\n",
    "                                              device=device)\n",
    "\n",
    "        fold_train_loss.append(train_loss)\n",
    "        fold_train_cccs.append(train_ccc)\n",
    "        fold_train_pccs.append(train_pcc)\n",
    "        fold_val_loss.append(val_loss)\n",
    "        fold_val_cccs.append(val_ccc)\n",
    "        fold_val_pccs.append(val_pcc)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch: {epoch + 1} | \"\n",
    "            f\"train_loss: {train_loss:.4f} | \"\n",
    "            f\"train_ccc: {train_ccc:.4f} | \"\n",
    "            f\"train_pcc: {train_pcc:.4f} | \"\n",
    "            f\"val_loss: {val_loss:.4f} | \"\n",
    "            f\"val_ccc: {val_ccc:.4f} | \"\n",
    "            f\"val_pcc: {val_pcc:.4f}\"\n",
    "        )\n",
    "\n",
    "        # Add loss and accuracy results to SummaryWriter\n",
    "        writer.add_scalars(main_tag=f\"Loss_{used_fold}\",\n",
    "                           tag_scalar_dict={\"train_loss\": train_loss,\n",
    "                                            \"val_loss\": val_loss},\n",
    "                           global_step=epoch)\n",
    "\n",
    "        writer.add_scalars(main_tag=f\"CCC_{used_fold}\",\n",
    "                           tag_scalar_dict={\"train_ccc\": train_ccc,\n",
    "                                            \"val_ccc\": val_ccc},\n",
    "                           global_step=epoch)\n",
    "        writer.add_scalars(main_tag=f\"PCC_{used_fold}\",\n",
    "                           tag_scalar_dict={\"train_pcc\": train_pcc,\n",
    "                                            \"val_pcc\": val_pcc},\n",
    "                           global_step=epoch)\n",
    "\n",
    "        # report the results\n",
    "        train.report({\"val_ccc\": val_ccc, \"val_pcc\": val_pcc, \"val_loss\": val_loss})\n",
    "\n",
    "    # evaluate results\n",
    "    best_ccc = max(fold_val_cccs)\n",
    "    best_epoch = fold_val_cccs.index(best_ccc)\n",
    "    best_epoch_pcc = fold_val_pccs[best_epoch]\n",
    "    best_epoch_loss = fold_val_loss[best_epoch]\n",
    "\n",
    "    # log hyperparameters and metrics\n",
    "    hparam_dict = {f\"{key}\": value for key, value in config.items()}\n",
    "    hparam_dict[\"best_epoch\"] = best_epoch\n",
    "    metric_dict = {\"hparam/best_val_ccc\": best_ccc,\n",
    "                   \"hparam/val_pcc\": best_epoch_pcc,\n",
    "                   \"hparam/val_loss\": best_epoch_loss}\n",
    "    writer.add_hparams(hparam_dict, metric_dict)\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "977dd369-31db-4a3a-8f5a-1c0ca34e1ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-05-26 22:41:58</td></tr>\n",
       "<tr><td>Running for: </td><td>03:25:39.50        </td></tr>\n",
       "<tr><td>Memory:      </td><td>27.2/63.7 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=16<br>Bracket: Iter 64.000: None | Iter 16.000: 0.42398631925780217 | Iter 4.000: 0.4232008387394205 | Iter 1.000: 0.3273905669805379<br>Logical resource usage: 0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  bs</th><th style=\"text-align: right;\">       do</th><th>loss_fn  </th><th style=\"text-align: right;\">     lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    val_ccc</th><th style=\"text-align: right;\">   val_pcc</th><th style=\"text-align: right;\">  val_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>tune_enet_aa95f_00000</td><td>TERMINATED</td><td>127.0.0.1:23156</td><td style=\"text-align: right;\"> 256</td><td style=\"text-align: right;\">0.371305 </td><td>MSE      </td><td style=\"text-align: right;\">0.054  </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">       1483.12  </td><td style=\"text-align: right;\"> 0.289464  </td><td style=\"text-align: right;\"> 0.386843 </td><td style=\"text-align: right;\"> 0.181286 </td></tr>\n",
       "<tr><td>tune_enet_aa95f_00001</td><td>TERMINATED</td><td>127.0.0.1:26948</td><td style=\"text-align: right;\"> 256</td><td style=\"text-align: right;\">0.11096  </td><td>MAE      </td><td style=\"text-align: right;\">0.00235</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">       1623.92  </td><td style=\"text-align: right;\"> 0.33012   </td><td style=\"text-align: right;\"> 0.366141 </td><td style=\"text-align: right;\"> 0.17963  </td></tr>\n",
       "<tr><td>tune_enet_aa95f_00002</td><td>TERMINATED</td><td>127.0.0.1:2744 </td><td style=\"text-align: right;\"> 256</td><td style=\"text-align: right;\">0.18713  </td><td>MSE      </td><td style=\"text-align: right;\">0.0347 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         83.8888</td><td style=\"text-align: right;\"> 0.129258  </td><td style=\"text-align: right;\"> 0.167679 </td><td style=\"text-align: right;\"> 0.132193 </td></tr>\n",
       "<tr><td>tune_enet_aa95f_00003</td><td>TERMINATED</td><td>127.0.0.1:7140 </td><td style=\"text-align: right;\">  64</td><td style=\"text-align: right;\">0.0447068</td><td>MSE      </td><td style=\"text-align: right;\">0.0001 </td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        319.175 </td><td style=\"text-align: right;\"> 0.250378  </td><td style=\"text-align: right;\"> 0.401975 </td><td style=\"text-align: right;\"> 0.0507523</td></tr>\n",
       "<tr><td>tune_enet_aa95f_00004</td><td>TERMINATED</td><td>127.0.0.1:3352 </td><td style=\"text-align: right;\">  64</td><td style=\"text-align: right;\">0.0444027</td><td>MAE      </td><td style=\"text-align: right;\">0.0281 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         84.1908</td><td style=\"text-align: right;\"> 0.155129  </td><td style=\"text-align: right;\"> 0.292617 </td><td style=\"text-align: right;\"> 0.482046 </td></tr>\n",
       "<tr><td>tune_enet_aa95f_00005</td><td>TERMINATED</td><td>127.0.0.1:2904 </td><td style=\"text-align: right;\"> 256</td><td style=\"text-align: right;\">0.0907329</td><td>MAE      </td><td style=\"text-align: right;\">0.00945</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        325.378 </td><td style=\"text-align: right;\"> 0.0221671 </td><td style=\"text-align: right;\"> 0.0152968</td><td style=\"text-align: right;\"> 0.241325 </td></tr>\n",
       "<tr><td>tune_enet_aa95f_00006</td><td>TERMINATED</td><td>127.0.0.1:30200</td><td style=\"text-align: right;\">  16</td><td style=\"text-align: right;\">0.265858 </td><td>MAE      </td><td style=\"text-align: right;\">0.00015</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         84.5605</td><td style=\"text-align: right;\"> 0.078357  </td><td style=\"text-align: right;\"> 0.159623 </td><td style=\"text-align: right;\"> 0.178246 </td></tr>\n",
       "<tr><td>tune_enet_aa95f_00007</td><td>TERMINATED</td><td>127.0.0.1:2288 </td><td style=\"text-align: right;\"> 128</td><td style=\"text-align: right;\">0.184449 </td><td>MAE      </td><td style=\"text-align: right;\">0.00895</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        320.517 </td><td style=\"text-align: right;\">-0.0233024 </td><td style=\"text-align: right;\">-0.0509643</td><td style=\"text-align: right;\"> 0.295654 </td></tr>\n",
       "<tr><td>tune_enet_aa95f_00008</td><td>TERMINATED</td><td>127.0.0.1:25092</td><td style=\"text-align: right;\">  16</td><td style=\"text-align: right;\">0.369446 </td><td>MAE      </td><td style=\"text-align: right;\">0.00785</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         84.6233</td><td style=\"text-align: right;\"> 0.0612178 </td><td style=\"text-align: right;\"> 0.130723 </td><td style=\"text-align: right;\"> 0.314655 </td></tr>\n",
       "<tr><td>tune_enet_aa95f_00009</td><td>TERMINATED</td><td>127.0.0.1:29132</td><td style=\"text-align: right;\"> 128</td><td style=\"text-align: right;\">0.29515  </td><td>MAE      </td><td style=\"text-align: right;\">0.0088 </td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">       1264.7   </td><td style=\"text-align: right;\"> 0.326764  </td><td style=\"text-align: right;\"> 0.377313 </td><td style=\"text-align: right;\"> 0.199    </td></tr>\n",
       "<tr><td>tune_enet_aa95f_00010</td><td>TERMINATED</td><td>127.0.0.1:7756 </td><td style=\"text-align: right;\"> 256</td><td style=\"text-align: right;\">0.0580774</td><td>MAE      </td><td style=\"text-align: right;\">0.00115</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">       1619.76  </td><td style=\"text-align: right;\"> 0.367289  </td><td style=\"text-align: right;\"> 0.399502 </td><td style=\"text-align: right;\"> 0.178166 </td></tr>\n",
       "<tr><td>tune_enet_aa95f_00011</td><td>TERMINATED</td><td>127.0.0.1:27696</td><td style=\"text-align: right;\"> 256</td><td style=\"text-align: right;\">0.327106 </td><td>MAE      </td><td style=\"text-align: right;\">0.01055</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">       1295.74  </td><td style=\"text-align: right;\"> 0.415587  </td><td style=\"text-align: right;\"> 0.468619 </td><td style=\"text-align: right;\"> 0.189355 </td></tr>\n",
       "<tr><td>tune_enet_aa95f_00012</td><td>TERMINATED</td><td>127.0.0.1:18724</td><td style=\"text-align: right;\">  32</td><td style=\"text-align: right;\">0.320334 </td><td>MAE      </td><td style=\"text-align: right;\">0.02085</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         85.3799</td><td style=\"text-align: right;\"> 0.0269643 </td><td style=\"text-align: right;\"> 0.0601286</td><td style=\"text-align: right;\"> 0.484996 </td></tr>\n",
       "<tr><td>tune_enet_aa95f_00013</td><td>TERMINATED</td><td>127.0.0.1:27696</td><td style=\"text-align: right;\">  16</td><td style=\"text-align: right;\">0.456874 </td><td>MSE      </td><td style=\"text-align: right;\">0.0317 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         86.3685</td><td style=\"text-align: right;\"> 0.0359299 </td><td style=\"text-align: right;\"> 0.115138 </td><td style=\"text-align: right;\"> 0.708758 </td></tr>\n",
       "<tr><td>tune_enet_aa95f_00014</td><td>TERMINATED</td><td>127.0.0.1:30068</td><td style=\"text-align: right;\">  64</td><td style=\"text-align: right;\">0.250674 </td><td>MSE      </td><td style=\"text-align: right;\">0.0249 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         84.3076</td><td style=\"text-align: right;\"> 0.132061  </td><td style=\"text-align: right;\"> 0.238041 </td><td style=\"text-align: right;\"> 0.248979 </td></tr>\n",
       "<tr><td>tune_enet_aa95f_00015</td><td>TERMINATED</td><td>127.0.0.1:26572</td><td style=\"text-align: right;\">  16</td><td style=\"text-align: right;\">0.302266 </td><td>MAE      </td><td style=\"text-align: right;\">0.0032 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         85.6443</td><td style=\"text-align: right;\"> 0.051089  </td><td style=\"text-align: right;\"> 0.102115 </td><td style=\"text-align: right;\"> 0.244724 </td></tr>\n",
       "<tr><td>tune_enet_aa95f_00016</td><td>TERMINATED</td><td>127.0.0.1:30592</td><td style=\"text-align: right;\"> 128</td><td style=\"text-align: right;\">0.280435 </td><td>MSE      </td><td style=\"text-align: right;\">0.0017 </td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        320.928 </td><td style=\"text-align: right;\"> 0.278369  </td><td style=\"text-align: right;\"> 0.348023 </td><td style=\"text-align: right;\"> 0.0545646</td></tr>\n",
       "<tr><td>tune_enet_aa95f_00017</td><td>TERMINATED</td><td>127.0.0.1:10960</td><td style=\"text-align: right;\"> 256</td><td style=\"text-align: right;\">0.234026 </td><td>MSE      </td><td style=\"text-align: right;\">0.00035</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">       1617.73  </td><td style=\"text-align: right;\"> 0.430178  </td><td style=\"text-align: right;\"> 0.49399  </td><td style=\"text-align: right;\"> 0.049293 </td></tr>\n",
       "<tr><td>tune_enet_aa95f_00018</td><td>TERMINATED</td><td>127.0.0.1:30156</td><td style=\"text-align: right;\">  32</td><td style=\"text-align: right;\">0.349109 </td><td>MSE      </td><td style=\"text-align: right;\">0.05295</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         84.164 </td><td style=\"text-align: right;\"> 0.00101707</td><td style=\"text-align: right;\"> 0.0031306</td><td style=\"text-align: right;\"> 0.839159 </td></tr>\n",
       "<tr><td>tune_enet_aa95f_00019</td><td>TERMINATED</td><td>127.0.0.1:28536</td><td style=\"text-align: right;\"> 256</td><td style=\"text-align: right;\">0.38872  </td><td>MSE      </td><td style=\"text-align: right;\">0.00075</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">       1296.97  </td><td style=\"text-align: right;\"> 0.411774  </td><td style=\"text-align: right;\"> 0.495842 </td><td style=\"text-align: right;\"> 0.0486662</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(tune_enet pid=23156)\u001b[0m cuda\n",
      "\u001b[36m(tune_enet pid=23156)\u001b[0m [INFO] Created a new pretrained EfficientNet-B0 model.\n",
      "\u001b[36m(tune_enet pid=23156)\u001b[0m Size of the training set: 19803\n",
      "\u001b[36m(tune_enet pid=23156)\u001b[0m Size of the validation set: 4915\n",
      "\u001b[36m(tune_enet pid=23156)\u001b[0m [INFO] Created SummaryWriter, saving to: C:\\local\\AIProject\\runs\\hp_tuning\\pretrained_enet\\fold_1_start_19-16-18\\2024-05-26_19-16-24...\n",
      "\u001b[36m(tune_enet pid=23156)\u001b[0m Epoch: 1 | train_loss: 0.7220 | train_ccc: 0.1955 | train_pcc: 0.4009 | val_loss: 0.7403 | val_ccc: 0.1457 | val_pcc: 0.3299\n",
      "\u001b[36m(tune_enet pid=23156)\u001b[0m Epoch: 2 | train_loss: 0.5861 | train_ccc: 0.2661 | train_pcc: 0.4778 | val_loss: 0.4555 | val_ccc: 0.1726 | val_pcc: 0.3899\n",
      "\u001b[36m(tune_enet pid=23156)\u001b[0m Epoch: 3 | train_loss: 0.3779 | train_ccc: 0.3217 | train_pcc: 0.4801 | val_loss: 0.3281 | val_ccc: 0.2518 | val_pcc: 0.4286\n",
      "\u001b[36m(tune_enet pid=23156)\u001b[0m Epoch: 4 | train_loss: 0.2883 | train_ccc: 0.3550 | train_pcc: 0.4866 | val_loss: 0.2273 | val_ccc: 0.2216 | val_pcc: 0.3755\n",
      "\u001b[36m(tune_enet pid=23156)\u001b[0m Epoch: 5 | train_loss: 0.3335 | train_ccc: 0.3327 | train_pcc: 0.4793 | val_loss: 0.4740 | val_ccc: 0.2374 | val_pcc: 0.4115\n",
      "\u001b[36m(tune_enet pid=23156)\u001b[0m Epoch: 6 | train_loss: 0.2571 | train_ccc: 0.3844 | train_pcc: 0.5102 | val_loss: 0.4282 | val_ccc: -0.1438 | val_pcc: -0.1833\n",
      "\u001b[36m(tune_enet pid=23156)\u001b[0m Epoch: 7 | train_loss: 0.2721 | train_ccc: 0.3343 | train_pcc: 0.4478 | val_loss: 0.3623 | val_ccc: 0.2309 | val_pcc: 0.3999\n",
      "\u001b[36m(tune_enet pid=23156)\u001b[0m Epoch: 8 | train_loss: 0.2479 | train_ccc: 0.3671 | train_pcc: 0.4865 | val_loss: 0.2743 | val_ccc: 0.2642 | val_pcc: 0.4452\n",
      "\u001b[36m(tune_enet pid=23156)\u001b[0m Epoch: 9 | train_loss: 0.2062 | train_ccc: 0.4196 | train_pcc: 0.5313 | val_loss: 0.2562 | val_ccc: 0.2369 | val_pcc: 0.4007\n",
      "\u001b[36m(tune_enet pid=23156)\u001b[0m Epoch: 10 | train_loss: 0.1850 | train_ccc: 0.4394 | train_pcc: 0.5372 | val_loss: 0.1655 | val_ccc: 0.3495 | val_pcc: 0.4370\n",
      "\u001b[36m(tune_enet pid=23156)\u001b[0m Epoch: 11 | train_loss: 0.1703 | train_ccc: 0.4516 | train_pcc: 0.5408 | val_loss: 0.3706 | val_ccc: 0.2372 | val_pcc: 0.3929\n",
      "\u001b[36m(tune_enet pid=23156)\u001b[0m Epoch: 12 | train_loss: 0.3159 | train_ccc: 0.3604 | train_pcc: 0.4872 | val_loss: 0.1734 | val_ccc: 0.3273 | val_pcc: 0.4125\n",
      "\u001b[36m(tune_enet pid=23156)\u001b[0m Epoch: 13 | train_loss: 0.2615 | train_ccc: 0.3816 | train_pcc: 0.5178 | val_loss: 0.2192 | val_ccc: 0.2756 | val_pcc: 0.3695\n",
      "\u001b[36m(tune_enet pid=23156)\u001b[0m Epoch: 14 | train_loss: 0.1810 | train_ccc: 0.4420 | train_pcc: 0.5363 | val_loss: 0.4838 | val_ccc: 0.2162 | val_pcc: 0.3835\n",
      "\u001b[36m(tune_enet pid=23156)\u001b[0m Epoch: 15 | train_loss: 0.2275 | train_ccc: 0.4129 | train_pcc: 0.5264 | val_loss: 0.1676 | val_ccc: 0.3333 | val_pcc: 0.4797\n",
      "\u001b[36m(tune_enet pid=23156)\u001b[0m Epoch: 16 | train_loss: 0.1686 | train_ccc: 0.4451 | train_pcc: 0.5346 | val_loss: 0.2300 | val_ccc: 0.3116 | val_pcc: 0.4265\n",
      "\u001b[36m(tune_enet pid=23156)\u001b[0m Epoch: 17 | train_loss: 0.2145 | train_ccc: 0.4111 | train_pcc: 0.5248 | val_loss: 0.1774 | val_ccc: 0.3681 | val_pcc: 0.4710\n",
      "\u001b[36m(tune_enet pid=23156)\u001b[0m Epoch: 18 | train_loss: 0.2541 | train_ccc: 0.3783 | train_pcc: 0.5140 | val_loss: 0.2333 | val_ccc: 0.1146 | val_pcc: 0.1764\n",
      "\u001b[36m(tune_enet pid=23156)\u001b[0m Epoch: 19 | train_loss: 0.1958 | train_ccc: 0.4292 | train_pcc: 0.5399 | val_loss: 0.1282 | val_ccc: 0.1531 | val_pcc: 0.1696\n",
      "\u001b[36m(tune_enet pid=23156)\u001b[0m Epoch: 20 | train_loss: 0.2091 | train_ccc: 0.4150 | train_pcc: 0.5202 | val_loss: 0.1813 | val_ccc: 0.2895 | val_pcc: 0.3868\n",
      "\u001b[36m(tune_enet pid=26948)\u001b[0m cuda\n",
      "\u001b[36m(tune_enet pid=26948)\u001b[0m [INFO] Created a new pretrained EfficientNet-B0 model.\n",
      "\u001b[36m(tune_enet pid=26948)\u001b[0m Size of the training set: 19803\n",
      "\u001b[36m(tune_enet pid=26948)\u001b[0m Size of the validation set: 4915\n",
      "\u001b[36m(tune_enet pid=26948)\u001b[0m [INFO] Created SummaryWriter, saving to: C:\\local\\AIProject\\runs\\hp_tuning\\pretrained_enet\\fold_1_start_19-16-18\\2024-05-26_19-41-12...\n",
      "\u001b[36m(tune_enet pid=26948)\u001b[0m Epoch: 1 | train_loss: 0.1515 | train_ccc: 0.6410 | train_pcc: 0.6693 | val_loss: 0.1897 | val_ccc: 0.1681 | val_pcc: 0.2516\n",
      "\u001b[36m(tune_enet pid=26948)\u001b[0m Epoch: 2 | train_loss: 0.1320 | train_ccc: 0.7329 | train_pcc: 0.7525 | val_loss: 0.1740 | val_ccc: 0.3446 | val_pcc: 0.4103\n",
      "\u001b[36m(tune_enet pid=26948)\u001b[0m \n",
      "\u001b[36m(tune_enet pid=26948)\u001b[0m Epoch: 3 | train_loss: 0.1284 | train_ccc: 0.7447 | train_pcc: 0.7619 | val_loss: 0.1887 | val_ccc: 0.2124 | val_pcc: 0.2771\n",
      "\u001b[36m(tune_enet pid=26948)\u001b[0m Epoch: 4 | train_loss: 0.1258 | train_ccc: 0.7575 | train_pcc: 0.7745 | val_loss: 0.1774 | val_ccc: 0.4284 | val_pcc: 0.4822\n",
      "\u001b[36m(tune_enet pid=26948)\u001b[0m Epoch: 5 | train_loss: 0.1229 | train_ccc: 0.7629 | train_pcc: 0.7792 | val_loss: 0.1843 | val_ccc: 0.4240 | val_pcc: 0.4753\n",
      "\u001b[36m(tune_enet pid=26948)\u001b[0m Epoch: 6 | train_loss: 0.1269 | train_ccc: 0.7646 | train_pcc: 0.7837 | val_loss: 0.1751 | val_ccc: 0.3468 | val_pcc: 0.3978\n",
      "\u001b[36m(tune_enet pid=26948)\u001b[0m Epoch: 7 | train_loss: 0.1219 | train_ccc: 0.7783 | train_pcc: 0.7937 | val_loss: 0.1775 | val_ccc: 0.3324 | val_pcc: 0.3896\n",
      "\u001b[36m(tune_enet pid=26948)\u001b[0m Epoch: 8 | train_loss: 0.1217 | train_ccc: 0.7773 | train_pcc: 0.7928 | val_loss: 0.1781 | val_ccc: 0.3582 | val_pcc: 0.3979\n",
      "\u001b[36m(tune_enet pid=26948)\u001b[0m Epoch: 9 | train_loss: 0.1234 | train_ccc: 0.7782 | train_pcc: 0.7944 | val_loss: 0.1784 | val_ccc: 0.4065 | val_pcc: 0.4423\n",
      "\u001b[36m(tune_enet pid=26948)\u001b[0m Epoch: 10 | train_loss: 0.1238 | train_ccc: 0.7780 | train_pcc: 0.7912 | val_loss: 0.1767 | val_ccc: 0.3781 | val_pcc: 0.4261\n",
      "\u001b[36m(tune_enet pid=26948)\u001b[0m Epoch: 11 | train_loss: 0.1242 | train_ccc: 0.7781 | train_pcc: 0.7929 | val_loss: 0.1726 | val_ccc: 0.3821 | val_pcc: 0.4190\n",
      "\u001b[36m(tune_enet pid=26948)\u001b[0m Epoch: 12 | train_loss: 0.1209 | train_ccc: 0.7833 | train_pcc: 0.7963 | val_loss: 0.1835 | val_ccc: 0.2937 | val_pcc: 0.3397\n",
      "\u001b[36m(tune_enet pid=26948)\u001b[0m Epoch: 13 | train_loss: 0.1245 | train_ccc: 0.7694 | train_pcc: 0.7844 | val_loss: 0.1796 | val_ccc: 0.4254 | val_pcc: 0.4625\n",
      "\u001b[36m(tune_enet pid=26948)\u001b[0m Epoch: 14 | train_loss: 0.1216 | train_ccc: 0.7847 | train_pcc: 0.7977 | val_loss: 0.1807 | val_ccc: 0.3284 | val_pcc: 0.3739\n",
      "\u001b[36m(tune_enet pid=26948)\u001b[0m Epoch: 15 | train_loss: 0.1231 | train_ccc: 0.7693 | train_pcc: 0.7834 | val_loss: 0.1794 | val_ccc: 0.3312 | val_pcc: 0.3880\n",
      "\u001b[36m(tune_enet pid=26948)\u001b[0m Epoch: 16 | train_loss: 0.1225 | train_ccc: 0.7770 | train_pcc: 0.7885 | val_loss: 0.1803 | val_ccc: 0.4267 | val_pcc: 0.4700\n",
      "\u001b[36m(tune_enet pid=26948)\u001b[0m Epoch: 17 | train_loss: 0.1200 | train_ccc: 0.7880 | train_pcc: 0.8008 | val_loss: 0.1806 | val_ccc: 0.4020 | val_pcc: 0.4516\n",
      "\u001b[36m(tune_enet pid=26948)\u001b[0m Epoch: 18 | train_loss: 0.1194 | train_ccc: 0.7851 | train_pcc: 0.7995 | val_loss: 0.1752 | val_ccc: 0.3836 | val_pcc: 0.4280\n",
      "\u001b[36m(tune_enet pid=26948)\u001b[0m Epoch: 19 | train_loss: 0.1192 | train_ccc: 0.7912 | train_pcc: 0.8021 | val_loss: 0.1744 | val_ccc: 0.3926 | val_pcc: 0.4390\n",
      "\u001b[36m(tune_enet pid=26948)\u001b[0m Epoch: 20 | train_loss: 0.1199 | train_ccc: 0.7899 | train_pcc: 0.8019 | val_loss: 0.1796 | val_ccc: 0.3301 | val_pcc: 0.3661\n",
      "\u001b[36m(tune_enet pid=2744)\u001b[0m cuda\n",
      "\u001b[36m(tune_enet pid=2744)\u001b[0m [INFO] Created a new pretrained EfficientNet-B0 model.\n",
      "\u001b[36m(tune_enet pid=2744)\u001b[0m Size of the training set: 19803\n",
      "\u001b[36m(tune_enet pid=2744)\u001b[0m Size of the validation set: 4915\n",
      "\u001b[36m(tune_enet pid=2744)\u001b[0m [INFO] Created SummaryWriter, saving to: C:\\local\\AIProject\\runs\\hp_tuning\\pretrained_enet\\fold_1_start_19-16-18\\2024-05-26_20-08-20...\n",
      "\u001b[36m(tune_enet pid=2744)\u001b[0m Epoch: 1 | train_loss: 0.3316 | train_ccc: 0.3893 | train_pcc: 0.5154 | val_loss: 0.1322 | val_ccc: 0.1293 | val_pcc: 0.1677\n",
      "\u001b[36m(tune_enet pid=7140)\u001b[0m cuda\n",
      "\u001b[36m(tune_enet pid=7140)\u001b[0m [INFO] Created a new pretrained EfficientNet-B0 model.\n",
      "\u001b[36m(tune_enet pid=7140)\u001b[0m Size of the training set: 19803\n",
      "\u001b[36m(tune_enet pid=7140)\u001b[0m Size of the validation set: 4915\n",
      "\u001b[36m(tune_enet pid=7140)\u001b[0m [INFO] Created SummaryWriter, saving to: C:\\local\\AIProject\\runs\\hp_tuning\\pretrained_enet\\fold_1_start_19-16-18\\2024-05-26_20-09-48...\n",
      "\u001b[36m(tune_enet pid=7140)\u001b[0m Epoch: 1 | train_loss: 0.0604 | train_ccc: 0.4200 | train_pcc: 0.4954 | val_loss: 0.0567 | val_ccc: 0.2267 | val_pcc: 0.3621\n",
      "\u001b[36m(tune_enet pid=7140)\u001b[0m Epoch: 2 | train_loss: 0.0453 | train_ccc: 0.5890 | train_pcc: 0.6630 | val_loss: 0.0534 | val_ccc: 0.2495 | val_pcc: 0.3898\n",
      "\u001b[36m(tune_enet pid=7140)\u001b[0m Epoch: 3 | train_loss: 0.0403 | train_ccc: 0.6425 | train_pcc: 0.7040 | val_loss: 0.0517 | val_ccc: 0.2505 | val_pcc: 0.3929\n",
      "\u001b[36m(tune_enet pid=7140)\u001b[0m Epoch: 4 | train_loss: 0.0384 | train_ccc: 0.6682 | train_pcc: 0.7260 | val_loss: 0.0508 | val_ccc: 0.2504 | val_pcc: 0.4020\n",
      "\u001b[36m(tune_enet pid=3352)\u001b[0m cuda\n",
      "\u001b[36m(tune_enet pid=3352)\u001b[0m [INFO] Created a new pretrained EfficientNet-B0 model.\n",
      "\u001b[36m(tune_enet pid=3352)\u001b[0m Size of the training set: 19803\n",
      "\u001b[36m(tune_enet pid=3352)\u001b[0m Size of the validation set: 4915\n",
      "\u001b[36m(tune_enet pid=3352)\u001b[0m [INFO] Created SummaryWriter, saving to: C:\\local\\AIProject\\runs\\hp_tuning\\pretrained_enet\\fold_1_start_19-16-18\\2024-05-26_20-15-12...\n",
      "\u001b[36m(tune_enet pid=3352)\u001b[0m Epoch: 1 | train_loss: 0.5154 | train_ccc: 0.3030 | train_pcc: 0.4442 | val_loss: 0.4820 | val_ccc: 0.1551 | val_pcc: 0.2926\n",
      "\u001b[36m(tune_enet pid=2904)\u001b[0m cuda\n",
      "\u001b[36m(tune_enet pid=2904)\u001b[0m [INFO] Created a new pretrained EfficientNet-B0 model.\n",
      "\u001b[36m(tune_enet pid=2904)\u001b[0m Size of the training set: 19803\n",
      "\u001b[36m(tune_enet pid=2904)\u001b[0m Size of the validation set: 4915\n",
      "\u001b[36m(tune_enet pid=2904)\u001b[0m [INFO] Created SummaryWriter, saving to: C:\\local\\AIProject\\runs\\hp_tuning\\pretrained_enet\\fold_1_start_19-16-18\\2024-05-26_20-16-41...\n",
      "\u001b[36m(tune_enet pid=2904)\u001b[0m Epoch: 1 | train_loss: 0.1862 | train_ccc: 0.5866 | train_pcc: 0.6110 | val_loss: 0.2008 | val_ccc: 0.4368 | val_pcc: 0.4856\n",
      "\u001b[36m(tune_enet pid=2904)\u001b[0m Epoch: 2 | train_loss: 0.1521 | train_ccc: 0.7251 | train_pcc: 0.7479 | val_loss: 0.2316 | val_ccc: 0.4142 | val_pcc: 0.4695\n",
      "\u001b[36m(tune_enet pid=2904)\u001b[0m Epoch: 3 | train_loss: 0.1500 | train_ccc: 0.7373 | train_pcc: 0.7567 | val_loss: 0.2150 | val_ccc: 0.4135 | val_pcc: 0.4440\n",
      "\u001b[36m(tune_enet pid=2904)\u001b[0m Epoch: 4 | train_loss: 0.1419 | train_ccc: 0.7447 | train_pcc: 0.7581 | val_loss: 0.2413 | val_ccc: 0.0222 | val_pcc: 0.0153\n",
      "\u001b[36m(tune_enet pid=30200)\u001b[0m cuda\n",
      "\u001b[36m(tune_enet pid=30200)\u001b[0m [INFO] Created a new pretrained EfficientNet-B0 model.\n",
      "\u001b[36m(tune_enet pid=30200)\u001b[0m Size of the training set: 19803\n",
      "\u001b[36m(tune_enet pid=30200)\u001b[0m Size of the validation set: 4915\n",
      "\u001b[36m(tune_enet pid=30200)\u001b[0m [INFO] Created SummaryWriter, saving to: C:\\local\\AIProject\\runs\\hp_tuning\\pretrained_enet\\fold_1_start_19-16-18\\2024-05-26_20-22-11...\n",
      "\u001b[36m(tune_enet pid=30200)\u001b[0m Epoch: 1 | train_loss: 0.1784 | train_ccc: 0.4274 | train_pcc: 0.5112 | val_loss: 0.1782 | val_ccc: 0.0784 | val_pcc: 0.1596\n",
      "\u001b[36m(tune_enet pid=2288)\u001b[0m cuda\n",
      "\u001b[36m(tune_enet pid=2288)\u001b[0m [INFO] Created a new pretrained EfficientNet-B0 model.\n",
      "\u001b[36m(tune_enet pid=2288)\u001b[0m Size of the training set: 19803\n",
      "\u001b[36m(tune_enet pid=2288)\u001b[0m Size of the validation set: 4915\n",
      "\u001b[36m(tune_enet pid=2288)\u001b[0m [INFO] Created SummaryWriter, saving to: C:\\local\\AIProject\\runs\\hp_tuning\\pretrained_enet\\fold_1_start_19-16-18\\2024-05-26_20-23-40...\n",
      "\u001b[36m(tune_enet pid=2288)\u001b[0m Epoch: 1 | train_loss: 0.1901 | train_ccc: 0.5999 | train_pcc: 0.6278 | val_loss: 0.1851 | val_ccc: 0.2914 | val_pcc: 0.3508\n",
      "\u001b[36m(tune_enet pid=2288)\u001b[0m Epoch: 2 | train_loss: 0.1726 | train_ccc: 0.6746 | train_pcc: 0.7029 | val_loss: 0.2023 | val_ccc: 0.2918 | val_pcc: 0.3736\n",
      "\u001b[36m(tune_enet pid=2288)\u001b[0m Epoch: 3 | train_loss: 0.1660 | train_ccc: 0.6781 | train_pcc: 0.6981 | val_loss: 0.2171 | val_ccc: 0.1455 | val_pcc: 0.1949\n",
      "\u001b[36m(tune_enet pid=2288)\u001b[0m Epoch: 4 | train_loss: 0.1719 | train_ccc: 0.6672 | train_pcc: 0.6950 | val_loss: 0.2957 | val_ccc: -0.0233 | val_pcc: -0.0510\n",
      "\u001b[36m(tune_enet pid=25092)\u001b[0m cuda\n",
      "\u001b[36m(tune_enet pid=25092)\u001b[0m [INFO] Created a new pretrained EfficientNet-B0 model.\n",
      "\u001b[36m(tune_enet pid=25092)\u001b[0m Size of the training set: 19803\n",
      "\u001b[36m(tune_enet pid=25092)\u001b[0m Size of the validation set: 4915\n",
      "\u001b[36m(tune_enet pid=25092)\u001b[0m [INFO] Created SummaryWriter, saving to: C:\\local\\AIProject\\runs\\hp_tuning\\pretrained_enet\\fold_1_start_19-16-18\\2024-05-26_20-29-04...\n",
      "\u001b[36m(tune_enet pid=25092)\u001b[0m Epoch: 1 | train_loss: 0.3628 | train_ccc: 0.2717 | train_pcc: 0.3458 | val_loss: 0.3147 | val_ccc: 0.0612 | val_pcc: 0.1307\n",
      "\u001b[36m(tune_enet pid=29132)\u001b[0m cuda\n",
      "\u001b[36m(tune_enet pid=29132)\u001b[0m [INFO] Created a new pretrained EfficientNet-B0 model.\n",
      "\u001b[36m(tune_enet pid=29132)\u001b[0m Size of the training set: 19803\n",
      "\u001b[36m(tune_enet pid=29132)\u001b[0m Size of the validation set: 4915\n",
      "\u001b[36m(tune_enet pid=29132)\u001b[0m [INFO] Created SummaryWriter, saving to: C:\\local\\AIProject\\runs\\hp_tuning\\pretrained_enet\\fold_1_start_19-16-18\\2024-05-26_20-30-33...\n",
      "\u001b[36m(tune_enet pid=29132)\u001b[0m Epoch: 1 | train_loss: 0.1997 | train_ccc: 0.5831 | train_pcc: 0.6153 | val_loss: 0.1921 | val_ccc: 0.2930 | val_pcc: 0.3552\n",
      "\u001b[36m(tune_enet pid=29132)\u001b[0m Epoch: 2 | train_loss: 0.1787 | train_ccc: 0.6551 | train_pcc: 0.6759 | val_loss: 0.1940 | val_ccc: 0.3252 | val_pcc: 0.3977\n",
      "\u001b[36m(tune_enet pid=29132)\u001b[0m Epoch: 3 | train_loss: 0.1800 | train_ccc: 0.6393 | train_pcc: 0.6622 | val_loss: 0.2204 | val_ccc: 0.3350 | val_pcc: 0.4247\n",
      "\u001b[36m(tune_enet pid=29132)\u001b[0m Epoch: 4 | train_loss: 0.1885 | train_ccc: 0.6189 | train_pcc: 0.6462 | val_loss: 0.2082 | val_ccc: 0.2602 | val_pcc: 0.3077\n",
      "\u001b[36m(tune_enet pid=29132)\u001b[0m Epoch: 5 | train_loss: 0.1804 | train_ccc: 0.6454 | train_pcc: 0.6662 | val_loss: 0.2048 | val_ccc: 0.2844 | val_pcc: 0.3637\n",
      "\u001b[36m(tune_enet pid=29132)\u001b[0m Epoch: 6 | train_loss: 0.1866 | train_ccc: 0.6243 | train_pcc: 0.6495 | val_loss: 0.2220 | val_ccc: 0.2521 | val_pcc: 0.3389\n",
      "\u001b[36m(tune_enet pid=29132)\u001b[0m Epoch: 7 | train_loss: 0.1837 | train_ccc: 0.6489 | train_pcc: 0.6777 | val_loss: 0.3019 | val_ccc: -0.0384 | val_pcc: -0.0819\n",
      "\u001b[36m(tune_enet pid=29132)\u001b[0m Epoch: 8 | train_loss: 0.1865 | train_ccc: 0.6311 | train_pcc: 0.6575 | val_loss: 0.2297 | val_ccc: 0.3345 | val_pcc: 0.4320\n",
      "\u001b[36m(tune_enet pid=29132)\u001b[0m Epoch: 9 | train_loss: 0.1865 | train_ccc: 0.6421 | train_pcc: 0.6709 | val_loss: 0.2214 | val_ccc: 0.3149 | val_pcc: 0.4092\n",
      "\u001b[36m(tune_enet pid=29132)\u001b[0m Epoch: 10 | train_loss: 0.1876 | train_ccc: 0.6323 | train_pcc: 0.6609 | val_loss: 0.1852 | val_ccc: 0.3150 | val_pcc: 0.3846\n",
      "\u001b[36m(tune_enet pid=29132)\u001b[0m Epoch: 11 | train_loss: 0.1846 | train_ccc: 0.6260 | train_pcc: 0.6500 | val_loss: 0.2445 | val_ccc: 0.2886 | val_pcc: 0.3775\n",
      "\u001b[36m(tune_enet pid=29132)\u001b[0m Epoch: 12 | train_loss: 0.1862 | train_ccc: 0.6188 | train_pcc: 0.6465 | val_loss: 0.2643 | val_ccc: 0.3074 | val_pcc: 0.3931\n",
      "\u001b[36m(tune_enet pid=29132)\u001b[0m Epoch: 13 | train_loss: 0.1837 | train_ccc: 0.6394 | train_pcc: 0.6627 | val_loss: 0.2639 | val_ccc: 0.2890 | val_pcc: 0.3838\n",
      "\u001b[36m(tune_enet pid=29132)\u001b[0m Epoch: 14 | train_loss: 0.1817 | train_ccc: 0.6464 | train_pcc: 0.6695 | val_loss: 0.2106 | val_ccc: 0.3284 | val_pcc: 0.4123\n",
      "\u001b[36m(tune_enet pid=29132)\u001b[0m Epoch: 15 | train_loss: 0.1869 | train_ccc: 0.6213 | train_pcc: 0.6472 | val_loss: 0.1899 | val_ccc: 0.2799 | val_pcc: 0.3774\n",
      "\u001b[36m(tune_enet pid=29132)\u001b[0m Epoch: 16 | train_loss: 0.1814 | train_ccc: 0.6381 | train_pcc: 0.6618 | val_loss: 0.1990 | val_ccc: 0.3268 | val_pcc: 0.3773\n",
      "\u001b[36m(tune_enet pid=7756)\u001b[0m cuda\n",
      "\u001b[36m(tune_enet pid=7756)\u001b[0m [INFO] Created a new pretrained EfficientNet-B0 model.\n",
      "\u001b[36m(tune_enet pid=7756)\u001b[0m Size of the training set: 19803\n",
      "\u001b[36m(tune_enet pid=7756)\u001b[0m Size of the validation set: 4915\n",
      "\u001b[36m(tune_enet pid=7756)\u001b[0m [INFO] Created SummaryWriter, saving to: C:\\local\\AIProject\\runs\\hp_tuning\\pretrained_enet\\fold_1_start_19-16-18\\2024-05-26_20-51-43...\n",
      "\u001b[36m(tune_enet pid=7756)\u001b[0m Epoch: 1 | train_loss: 0.1615 | train_ccc: 0.5823 | train_pcc: 0.6188 | val_loss: 0.1702 | val_ccc: 0.4206 | val_pcc: 0.5037\n",
      "\u001b[36m(tune_enet pid=7756)\u001b[0m Epoch: 2 | train_loss: 0.1314 | train_ccc: 0.7133 | train_pcc: 0.7472 | val_loss: 0.1715 | val_ccc: 0.4214 | val_pcc: 0.5007\n",
      "\u001b[36m(tune_enet pid=7756)\u001b[0m Epoch: 3 | train_loss: 0.1233 | train_ccc: 0.7434 | train_pcc: 0.7740 | val_loss: 0.1688 | val_ccc: 0.3731 | val_pcc: 0.4464\n",
      "\u001b[36m(tune_enet pid=7756)\u001b[0m Epoch: 4 | train_loss: 0.1210 | train_ccc: 0.7581 | train_pcc: 0.7860 | val_loss: 0.1693 | val_ccc: 0.4180 | val_pcc: 0.4890\n",
      "\u001b[36m(tune_enet pid=7756)\u001b[0m Epoch: 5 | train_loss: 0.1190 | train_ccc: 0.7672 | train_pcc: 0.7929 | val_loss: 0.1818 | val_ccc: 0.4402 | val_pcc: 0.5021\n",
      "\u001b[36m(tune_enet pid=7756)\u001b[0m Epoch: 6 | train_loss: 0.1184 | train_ccc: 0.7734 | train_pcc: 0.7941 | val_loss: 0.1711 | val_ccc: 0.3980 | val_pcc: 0.4556\n",
      "\u001b[36m(tune_enet pid=7756)\u001b[0m Epoch: 7 | train_loss: 0.1146 | train_ccc: 0.7848 | train_pcc: 0.8071 | val_loss: 0.1743 | val_ccc: 0.3854 | val_pcc: 0.4397\n",
      "\u001b[36m(tune_enet pid=7756)\u001b[0m Epoch: 8 | train_loss: 0.1151 | train_ccc: 0.7871 | train_pcc: 0.8086 | val_loss: 0.1728 | val_ccc: 0.3633 | val_pcc: 0.4205\n",
      "\u001b[36m(tune_enet pid=7756)\u001b[0m Epoch: 9 | train_loss: 0.1130 | train_ccc: 0.7962 | train_pcc: 0.8159 | val_loss: 0.1741 | val_ccc: 0.3927 | val_pcc: 0.4331\n",
      "\u001b[36m(tune_enet pid=7756)\u001b[0m Epoch: 10 | train_loss: 0.1123 | train_ccc: 0.7999 | train_pcc: 0.8190 | val_loss: 0.1856 | val_ccc: 0.2453 | val_pcc: 0.3242\n",
      "\u001b[36m(tune_enet pid=7756)\u001b[0m Epoch: 11 | train_loss: 0.1130 | train_ccc: 0.8007 | train_pcc: 0.8189 | val_loss: 0.1760 | val_ccc: 0.3361 | val_pcc: 0.3904\n",
      "\u001b[36m(tune_enet pid=7756)\u001b[0m Epoch: 12 | train_loss: 0.1122 | train_ccc: 0.7996 | train_pcc: 0.8169 | val_loss: 0.1739 | val_ccc: 0.3814 | val_pcc: 0.4254\n",
      "\u001b[36m(tune_enet pid=7756)\u001b[0m Epoch: 13 | train_loss: 0.1115 | train_ccc: 0.8069 | train_pcc: 0.8240 | val_loss: 0.1764 | val_ccc: 0.4018 | val_pcc: 0.4494\n",
      "\u001b[36m(tune_enet pid=7756)\u001b[0m Epoch: 14 | train_loss: 0.1105 | train_ccc: 0.8111 | train_pcc: 0.8279 | val_loss: 0.1760 | val_ccc: 0.3998 | val_pcc: 0.4516\n",
      "\u001b[36m(tune_enet pid=7756)\u001b[0m Epoch: 15 | train_loss: 0.1111 | train_ccc: 0.8067 | train_pcc: 0.8231 | val_loss: 0.1767 | val_ccc: 0.4010 | val_pcc: 0.4451\n",
      "\u001b[36m(tune_enet pid=7756)\u001b[0m Epoch: 16 | train_loss: 0.1102 | train_ccc: 0.8107 | train_pcc: 0.8260 | val_loss: 0.1791 | val_ccc: 0.4213 | val_pcc: 0.4644\n",
      "\u001b[36m(tune_enet pid=7756)\u001b[0m Epoch: 17 | train_loss: 0.1120 | train_ccc: 0.7972 | train_pcc: 0.8122 | val_loss: 0.1767 | val_ccc: 0.4045 | val_pcc: 0.4462\n",
      "\u001b[36m(tune_enet pid=7756)\u001b[0m Epoch: 18 | train_loss: 0.1092 | train_ccc: 0.8109 | train_pcc: 0.8267 | val_loss: 0.1833 | val_ccc: 0.3939 | val_pcc: 0.4383\n",
      "\u001b[36m(tune_enet pid=7756)\u001b[0m Epoch: 19 | train_loss: 0.1100 | train_ccc: 0.8137 | train_pcc: 0.8281 | val_loss: 0.1749 | val_ccc: 0.3736 | val_pcc: 0.4105\n",
      "\u001b[36m(tune_enet pid=7756)\u001b[0m Epoch: 20 | train_loss: 0.1099 | train_ccc: 0.8114 | train_pcc: 0.8272 | val_loss: 0.1782 | val_ccc: 0.3673 | val_pcc: 0.3995\n",
      "\u001b[36m(tune_enet pid=27696)\u001b[0m cuda\n",
      "\u001b[36m(tune_enet pid=27696)\u001b[0m [INFO] Created a new pretrained EfficientNet-B0 model.\n",
      "\u001b[36m(tune_enet pid=27696)\u001b[0m Size of the training set: 19803\n",
      "\u001b[36m(tune_enet pid=27696)\u001b[0m Size of the validation set: 4915\n",
      "\u001b[36m(tune_enet pid=27696)\u001b[0m [INFO] Created SummaryWriter, saving to: C:\\local\\AIProject\\runs\\hp_tuning\\pretrained_enet\\fold_1_start_19-16-18\\2024-05-26_21-18-48...\n",
      "\u001b[36m(tune_enet pid=27696)\u001b[0m Epoch: 1 | train_loss: 0.2224 | train_ccc: 0.5163 | train_pcc: 0.5617 | val_loss: 0.1925 | val_ccc: 0.4543 | val_pcc: 0.4982\n",
      "\u001b[36m(tune_enet pid=27696)\u001b[0m Epoch: 2 | train_loss: 0.1664 | train_ccc: 0.6695 | train_pcc: 0.6845 | val_loss: 0.2042 | val_ccc: 0.4260 | val_pcc: 0.4778\n",
      "\u001b[36m(tune_enet pid=27696)\u001b[0m Epoch: 3 | train_loss: 0.1719 | train_ccc: 0.6579 | train_pcc: 0.6748 | val_loss: 0.2234 | val_ccc: 0.2238 | val_pcc: 0.2264\n",
      "\u001b[36m(tune_enet pid=27696)\u001b[0m Epoch: 4 | train_loss: 0.1791 | train_ccc: 0.6486 | train_pcc: 0.6775 | val_loss: 0.1891 | val_ccc: 0.4042 | val_pcc: 0.4519\n",
      "\u001b[36m(tune_enet pid=27696)\u001b[0m Epoch: 5 | train_loss: 0.1718 | train_ccc: 0.6571 | train_pcc: 0.6741 | val_loss: 0.1996 | val_ccc: 0.4377 | val_pcc: 0.4842\n",
      "\u001b[36m(tune_enet pid=27696)\u001b[0m Epoch: 6 | train_loss: 0.1705 | train_ccc: 0.6624 | train_pcc: 0.6778 | val_loss: 0.2049 | val_ccc: 0.4209 | val_pcc: 0.4858\n",
      "\u001b[36m(tune_enet pid=27696)\u001b[0m Epoch: 7 | train_loss: 0.1672 | train_ccc: 0.6688 | train_pcc: 0.6836 | val_loss: 0.1961 | val_ccc: 0.3336 | val_pcc: 0.3653\n",
      "\u001b[36m(tune_enet pid=27696)\u001b[0m Epoch: 8 | train_loss: 0.1716 | train_ccc: 0.6579 | train_pcc: 0.6775 | val_loss: 0.2094 | val_ccc: 0.4024 | val_pcc: 0.4772\n",
      "\u001b[36m(tune_enet pid=27696)\u001b[0m Epoch: 9 | train_loss: 0.1699 | train_ccc: 0.6672 | train_pcc: 0.6853 | val_loss: 0.1993 | val_ccc: 0.1695 | val_pcc: 0.2145\n",
      "\u001b[36m(tune_enet pid=27696)\u001b[0m Epoch: 10 | train_loss: 0.1768 | train_ccc: 0.6412 | train_pcc: 0.6634 | val_loss: 0.1952 | val_ccc: 0.3253 | val_pcc: 0.3680\n",
      "\u001b[36m(tune_enet pid=27696)\u001b[0m Epoch: 11 | train_loss: 0.1770 | train_ccc: 0.6542 | train_pcc: 0.6751 | val_loss: 0.1949 | val_ccc: 0.3217 | val_pcc: 0.3756\n",
      "\u001b[36m(tune_enet pid=27696)\u001b[0m Epoch: 12 | train_loss: 0.1689 | train_ccc: 0.6521 | train_pcc: 0.6675 | val_loss: 0.1942 | val_ccc: 0.4171 | val_pcc: 0.4658\n",
      "\u001b[36m(tune_enet pid=27696)\u001b[0m Epoch: 13 | train_loss: 0.1698 | train_ccc: 0.6601 | train_pcc: 0.6781 | val_loss: 0.2026 | val_ccc: 0.3563 | val_pcc: 0.4185\n",
      "\u001b[36m(tune_enet pid=27696)\u001b[0m Epoch: 14 | train_loss: 0.1701 | train_ccc: 0.6677 | train_pcc: 0.6862 | val_loss: 0.2055 | val_ccc: 0.4003 | val_pcc: 0.4440\n",
      "\u001b[36m(tune_enet pid=27696)\u001b[0m Epoch: 15 | train_loss: 0.1656 | train_ccc: 0.6698 | train_pcc: 0.6820 | val_loss: 0.1906 | val_ccc: 0.3595 | val_pcc: 0.4112\n",
      "\u001b[36m(tune_enet pid=27696)\u001b[0m Epoch: 16 | train_loss: 0.1726 | train_ccc: 0.6491 | train_pcc: 0.6672 | val_loss: 0.1894 | val_ccc: 0.4156 | val_pcc: 0.4686\n",
      "\u001b[36m(tune_enet pid=18724)\u001b[0m cuda\n",
      "\u001b[36m(tune_enet pid=18724)\u001b[0m \n",
      "\u001b[36m(tune_enet pid=18724)\u001b[0m [INFO] Created a new pretrained EfficientNet-B0 model.\n",
      "\u001b[36m(tune_enet pid=18724)\u001b[0m Size of the training set: 19803\n",
      "\u001b[36m(tune_enet pid=18724)\u001b[0m Size of the validation set: 4915\n",
      "\u001b[36m(tune_enet pid=18724)\u001b[0m [INFO] Created SummaryWriter, saving to: C:\\local\\AIProject\\runs\\hp_tuning\\pretrained_enet\\fold_1_start_19-16-18\\2024-05-26_21-40-28...\n",
      "\u001b[36m(tune_enet pid=18724)\u001b[0m Epoch: 1 | train_loss: 0.5271 | train_ccc: 0.2150 | train_pcc: 0.3208 | val_loss: 0.4850 | val_ccc: 0.0270 | val_pcc: 0.0601\n",
      "\u001b[36m(tune_enet pid=27696)\u001b[0m cuda\n",
      "\u001b[36m(tune_enet pid=27696)\u001b[0m [INFO] Created a new pretrained EfficientNet-B0 model.\n",
      "\u001b[36m(tune_enet pid=27696)\u001b[0m Size of the training set: 19803\n",
      "\u001b[36m(tune_enet pid=27696)\u001b[0m Size of the validation set: 4915\n",
      "\u001b[36m(tune_enet pid=27696)\u001b[0m [INFO] Created SummaryWriter, saving to: C:\\local\\AIProject\\runs\\hp_tuning\\pretrained_enet\\fold_1_start_19-16-18\\2024-05-26_21-41-58...\n",
      "\u001b[36m(tune_enet pid=27696)\u001b[0m Epoch: 1 | train_loss: 0.7230 | train_ccc: 0.1625 | train_pcc: 0.3436 | val_loss: 0.7088 | val_ccc: 0.0359 | val_pcc: 0.1151\n",
      "\u001b[36m(tune_enet pid=30068)\u001b[0m cuda\n",
      "\u001b[36m(tune_enet pid=30068)\u001b[0m [INFO] Created a new pretrained EfficientNet-B0 model.\n",
      "\u001b[36m(tune_enet pid=30068)\u001b[0m Size of the training set: 19803\n",
      "\u001b[36m(tune_enet pid=30068)\u001b[0m Size of the validation set: 4915\n",
      "\u001b[36m(tune_enet pid=30068)\u001b[0m [INFO] Created SummaryWriter, saving to: C:\\local\\AIProject\\runs\\hp_tuning\\pretrained_enet\\fold_1_start_19-16-18\\2024-05-26_21-43-29...\n",
      "\u001b[36m(tune_enet pid=30068)\u001b[0m Epoch: 1 | train_loss: 0.2348 | train_ccc: 0.3949 | train_pcc: 0.5088 | val_loss: 0.2490 | val_ccc: 0.1321 | val_pcc: 0.2380\n",
      "\u001b[36m(tune_enet pid=26572)\u001b[0m cuda\n",
      "\u001b[36m(tune_enet pid=26572)\u001b[0m [INFO] Created a new pretrained EfficientNet-B0 model.\n",
      "\u001b[36m(tune_enet pid=26572)\u001b[0m Size of the training set: 19803\n",
      "\u001b[36m(tune_enet pid=26572)\u001b[0m Size of the validation set: 4915\n",
      "\u001b[36m(tune_enet pid=26572)\u001b[0m [INFO] Created SummaryWriter, saving to: C:\\local\\AIProject\\runs\\hp_tuning\\pretrained_enet\\fold_1_start_19-16-18\\2024-05-26_21-44-58...\n",
      "\u001b[36m(tune_enet pid=26572)\u001b[0m Epoch: 1 | train_loss: 0.2207 | train_ccc: 0.4736 | train_pcc: 0.5248 | val_loss: 0.2447 | val_ccc: 0.0511 | val_pcc: 0.1021\n",
      "\u001b[36m(tune_enet pid=30592)\u001b[0m cuda\n",
      "\u001b[36m(tune_enet pid=30592)\u001b[0m [INFO] Created a new pretrained EfficientNet-B0 model.\n",
      "\u001b[36m(tune_enet pid=30592)\u001b[0m Size of the training set: 19803\n",
      "\u001b[36m(tune_enet pid=30592)\u001b[0m Size of the validation set: 4915\n",
      "\u001b[36m(tune_enet pid=30592)\u001b[0m [INFO] Created SummaryWriter, saving to: C:\\local\\AIProject\\runs\\hp_tuning\\pretrained_enet\\fold_1_start_19-16-18\\2024-05-26_21-46-28...\n",
      "\u001b[36m(tune_enet pid=30592)\u001b[0m Epoch: 1 | train_loss: 0.0557 | train_ccc: 0.6029 | train_pcc: 0.6242 | val_loss: 0.0585 | val_ccc: 0.3110 | val_pcc: 0.3993\n",
      "\u001b[36m(tune_enet pid=30592)\u001b[0m Epoch: 2 | train_loss: 0.0396 | train_ccc: 0.7204 | train_pcc: 0.7328 | val_loss: 0.0552 | val_ccc: 0.3248 | val_pcc: 0.4112\n",
      "\u001b[36m(tune_enet pid=30592)\u001b[0m Epoch: 3 | train_loss: 0.0390 | train_ccc: 0.7284 | train_pcc: 0.7415 | val_loss: 0.0532 | val_ccc: 0.3252 | val_pcc: 0.3889\n",
      "\u001b[36m(tune_enet pid=30592)\u001b[0m Epoch: 4 | train_loss: 0.0367 | train_ccc: 0.7417 | train_pcc: 0.7539 | val_loss: 0.0546 | val_ccc: 0.2784 | val_pcc: 0.3480\n",
      "\u001b[36m(tune_enet pid=10960)\u001b[0m cuda\n",
      "\u001b[36m(tune_enet pid=10960)\u001b[0m [INFO] Created a new pretrained EfficientNet-B0 model.\n",
      "\u001b[36m(tune_enet pid=10960)\u001b[0m Size of the training set: 19803\n",
      "\u001b[36m(tune_enet pid=10960)\u001b[0m Size of the validation set: 4915\n",
      "\u001b[36m(tune_enet pid=10960)\u001b[0m [INFO] Created SummaryWriter, saving to: C:\\local\\AIProject\\runs\\hp_tuning\\pretrained_enet\\fold_1_start_19-16-18\\2024-05-26_21-51-53...\n",
      "\u001b[36m(tune_enet pid=10960)\u001b[0m Epoch: 1 | train_loss: 0.0654 | train_ccc: 0.4603 | train_pcc: 0.4857 | val_loss: 0.0585 | val_ccc: 0.3764 | val_pcc: 0.4669\n",
      "\u001b[36m(tune_enet pid=10960)\u001b[0m Epoch: 2 | train_loss: 0.0467 | train_ccc: 0.6160 | train_pcc: 0.6443 | val_loss: 0.0524 | val_ccc: 0.4118 | val_pcc: 0.4978\n",
      "\u001b[36m(tune_enet pid=10960)\u001b[0m Epoch: 3 | train_loss: 0.0423 | train_ccc: 0.6589 | train_pcc: 0.6855 | val_loss: 0.0512 | val_ccc: 0.4336 | val_pcc: 0.5083\n",
      "\u001b[36m(tune_enet pid=10960)\u001b[0m Epoch: 4 | train_loss: 0.0390 | train_ccc: 0.6921 | train_pcc: 0.7158 | val_loss: 0.0497 | val_ccc: 0.4357 | val_pcc: 0.5078\n",
      "\u001b[36m(tune_enet pid=10960)\u001b[0m Epoch: 5 | train_loss: 0.0382 | train_ccc: 0.7009 | train_pcc: 0.7227 | val_loss: 0.0527 | val_ccc: 0.3371 | val_pcc: 0.4348\n",
      "\u001b[36m(tune_enet pid=10960)\u001b[0m Epoch: 6 | train_loss: 0.0368 | train_ccc: 0.7171 | train_pcc: 0.7377 | val_loss: 0.0489 | val_ccc: 0.3994 | val_pcc: 0.4833\n",
      "\u001b[36m(tune_enet pid=10960)\u001b[0m Epoch: 7 | train_loss: 0.0353 | train_ccc: 0.7245 | train_pcc: 0.7447 | val_loss: 0.0495 | val_ccc: 0.4479 | val_pcc: 0.5073\n",
      "\u001b[36m(tune_enet pid=10960)\u001b[0m Epoch: 8 | train_loss: 0.0339 | train_ccc: 0.7340 | train_pcc: 0.7554 | val_loss: 0.0516 | val_ccc: 0.4513 | val_pcc: 0.5095\n",
      "\u001b[36m(tune_enet pid=10960)\u001b[0m Epoch: 9 | train_loss: 0.0332 | train_ccc: 0.7446 | train_pcc: 0.7630 | val_loss: 0.0489 | val_ccc: 0.4153 | val_pcc: 0.4880\n",
      "\u001b[36m(tune_enet pid=10960)\u001b[0m Epoch: 10 | train_loss: 0.0327 | train_ccc: 0.7477 | train_pcc: 0.7656 | val_loss: 0.0492 | val_ccc: 0.4417 | val_pcc: 0.5038\n",
      "\u001b[36m(tune_enet pid=10960)\u001b[0m Epoch: 11 | train_loss: 0.0328 | train_ccc: 0.7497 | train_pcc: 0.7683 | val_loss: 0.0487 | val_ccc: 0.4355 | val_pcc: 0.4993\n",
      "\u001b[36m(tune_enet pid=10960)\u001b[0m Epoch: 12 | train_loss: 0.0324 | train_ccc: 0.7516 | train_pcc: 0.7704 | val_loss: 0.0491 | val_ccc: 0.4141 | val_pcc: 0.4873\n",
      "\u001b[36m(tune_enet pid=10960)\u001b[0m Epoch: 13 | train_loss: 0.0326 | train_ccc: 0.7511 | train_pcc: 0.7686 | val_loss: 0.0488 | val_ccc: 0.4216 | val_pcc: 0.4919\n",
      "\u001b[36m(tune_enet pid=10960)\u001b[0m Epoch: 14 | train_loss: 0.0310 | train_ccc: 0.7634 | train_pcc: 0.7802 | val_loss: 0.0495 | val_ccc: 0.4452 | val_pcc: 0.5047\n",
      "\u001b[36m(tune_enet pid=10960)\u001b[0m Epoch: 15 | train_loss: 0.0306 | train_ccc: 0.7641 | train_pcc: 0.7812 | val_loss: 0.0491 | val_ccc: 0.4358 | val_pcc: 0.4958\n",
      "\u001b[36m(tune_enet pid=10960)\u001b[0m Epoch: 16 | train_loss: 0.0307 | train_ccc: 0.7643 | train_pcc: 0.7822 | val_loss: 0.0504 | val_ccc: 0.4549 | val_pcc: 0.5138\n",
      "\u001b[36m(tune_enet pid=10960)\u001b[0m Epoch: 17 | train_loss: 0.0310 | train_ccc: 0.7656 | train_pcc: 0.7803 | val_loss: 0.0490 | val_ccc: 0.4415 | val_pcc: 0.5020\n",
      "\u001b[36m(tune_enet pid=10960)\u001b[0m Epoch: 18 | train_loss: 0.0301 | train_ccc: 0.7694 | train_pcc: 0.7872 | val_loss: 0.0499 | val_ccc: 0.4421 | val_pcc: 0.5008\n",
      "\u001b[36m(tune_enet pid=10960)\u001b[0m Epoch: 19 | train_loss: 0.0300 | train_ccc: 0.7723 | train_pcc: 0.7877 | val_loss: 0.0512 | val_ccc: 0.4452 | val_pcc: 0.5034\n",
      "\u001b[36m(tune_enet pid=10960)\u001b[0m Epoch: 20 | train_loss: 0.0305 | train_ccc: 0.7692 | train_pcc: 0.7853 | val_loss: 0.0493 | val_ccc: 0.4302 | val_pcc: 0.4940\n",
      "\u001b[36m(tune_enet pid=30156)\u001b[0m cuda\n",
      "\u001b[36m(tune_enet pid=30156)\u001b[0m [INFO] Created a new pretrained EfficientNet-B0 model.\n",
      "\u001b[36m(tune_enet pid=30156)\u001b[0m Size of the training set: 19803\n",
      "\u001b[36m(tune_enet pid=30156)\u001b[0m Size of the validation set: 4915\n",
      "\u001b[36m(tune_enet pid=30156)\u001b[0m [INFO] Created SummaryWriter, saving to: C:\\local\\AIProject\\runs\\hp_tuning\\pretrained_enet\\fold_1_start_19-16-18\\2024-05-26_22-18-55...\n",
      "\u001b[36m(tune_enet pid=30156)\u001b[0m Epoch: 1 | train_loss: 0.7705 | train_ccc: 0.1538 | train_pcc: 0.3569 | val_loss: 0.8392 | val_ccc: 0.0010 | val_pcc: 0.0031\n",
      "\u001b[36m(tune_enet pid=28536)\u001b[0m cuda\n",
      "\u001b[36m(tune_enet pid=28536)\u001b[0m [INFO] Created a new pretrained EfficientNet-B0 model.\n",
      "\u001b[36m(tune_enet pid=28536)\u001b[0m Size of the training set: 19803\n",
      "\u001b[36m(tune_enet pid=28536)\u001b[0m Size of the validation set: 4915\n",
      "\u001b[36m(tune_enet pid=28536)\u001b[0m [INFO] Created SummaryWriter, saving to: C:\\local\\AIProject\\runs\\hp_tuning\\pretrained_enet\\fold_1_start_19-16-18\\2024-05-26_22-20-23...\n",
      "\u001b[36m(tune_enet pid=28536)\u001b[0m Epoch: 1 | train_loss: 0.0613 | train_ccc: 0.5308 | train_pcc: 0.5465 | val_loss: 0.0528 | val_ccc: 0.4092 | val_pcc: 0.5003\n",
      "\u001b[36m(tune_enet pid=28536)\u001b[0m Epoch: 2 | train_loss: 0.0442 | train_ccc: 0.6643 | train_pcc: 0.6790 | val_loss: 0.0487 | val_ccc: 0.4366 | val_pcc: 0.5153\n",
      "\u001b[36m(tune_enet pid=28536)\u001b[0m \n",
      "\u001b[36m(tune_enet pid=28536)\u001b[0m Epoch: 3 | train_loss: 0.0413 | train_ccc: 0.6860 | train_pcc: 0.7026 | val_loss: 0.0614 | val_ccc: 0.4400 | val_pcc: 0.5081\n",
      "\u001b[36m(tune_enet pid=28536)\u001b[0m Epoch: 4 | train_loss: 0.0392 | train_ccc: 0.7108 | train_pcc: 0.7260 | val_loss: 0.0483 | val_ccc: 0.4400 | val_pcc: 0.5141\n",
      "\u001b[36m(tune_enet pid=28536)\u001b[0m Epoch: 5 | train_loss: 0.0378 | train_ccc: 0.7163 | train_pcc: 0.7311 | val_loss: 0.0549 | val_ccc: 0.4519 | val_pcc: 0.5138\n",
      "\u001b[36m(tune_enet pid=28536)\u001b[0m Epoch: 6 | train_loss: 0.0372 | train_ccc: 0.7217 | train_pcc: 0.7368 | val_loss: 0.0507 | val_ccc: 0.4512 | val_pcc: 0.5160\n",
      "\u001b[36m(tune_enet pid=28536)\u001b[0m Epoch: 7 | train_loss: 0.0363 | train_ccc: 0.7259 | train_pcc: 0.7411 | val_loss: 0.0485 | val_ccc: 0.4293 | val_pcc: 0.4987\n",
      "\u001b[36m(tune_enet pid=28536)\u001b[0m Epoch: 8 | train_loss: 0.0364 | train_ccc: 0.7258 | train_pcc: 0.7415 | val_loss: 0.0500 | val_ccc: 0.4270 | val_pcc: 0.4970\n",
      "\u001b[36m(tune_enet pid=28536)\u001b[0m Epoch: 9 | train_loss: 0.0354 | train_ccc: 0.7332 | train_pcc: 0.7494 | val_loss: 0.0520 | val_ccc: 0.4528 | val_pcc: 0.5163\n",
      "\u001b[36m(tune_enet pid=28536)\u001b[0m Epoch: 10 | train_loss: 0.0352 | train_ccc: 0.7372 | train_pcc: 0.7502 | val_loss: 0.0500 | val_ccc: 0.4409 | val_pcc: 0.5067\n",
      "\u001b[36m(tune_enet pid=28536)\u001b[0m Epoch: 11 | train_loss: 0.0348 | train_ccc: 0.7382 | train_pcc: 0.7543 | val_loss: 0.0490 | val_ccc: 0.4132 | val_pcc: 0.4931\n",
      "\u001b[36m(tune_enet pid=28536)\u001b[0m Epoch: 12 | train_loss: 0.0353 | train_ccc: 0.7342 | train_pcc: 0.7500 | val_loss: 0.0490 | val_ccc: 0.4401 | val_pcc: 0.5081\n",
      "\u001b[36m(tune_enet pid=28536)\u001b[0m Epoch: 13 | train_loss: 0.0367 | train_ccc: 0.7301 | train_pcc: 0.7443 | val_loss: 0.0504 | val_ccc: 0.4483 | val_pcc: 0.5126\n",
      "\u001b[36m(tune_enet pid=28536)\u001b[0m Epoch: 14 | train_loss: 0.0374 | train_ccc: 0.7271 | train_pcc: 0.7417 | val_loss: 0.0559 | val_ccc: 0.4464 | val_pcc: 0.5054\n",
      "\u001b[36m(tune_enet pid=28536)\u001b[0m Epoch: 15 | train_loss: 0.0353 | train_ccc: 0.7365 | train_pcc: 0.7497 | val_loss: 0.0505 | val_ccc: 0.4405 | val_pcc: 0.5035\n",
      "\u001b[36m(tune_enet pid=28536)\u001b[0m Epoch: 16 | train_loss: 0.0362 | train_ccc: 0.7317 | train_pcc: 0.7465 | val_loss: 0.0487 | val_ccc: 0.4118 | val_pcc: 0.4958\n"
     ]
    }
   ],
   "source": [
    "# first hyperparameter tuning run\n",
    "search_space = {\n",
    "    \"bs\": tune.choice([16, 32, 64, 128, 256]),\n",
    "    \"do\": tune.uniform(0.0, 0.5),\n",
    "    \"loss_fn\": tune.choice([\"MAE\", \"MSE\"]),\n",
    "    \"lr\": tune.qloguniform(1e-4, 1e-1, 5e-5),\n",
    "    \"aug\": False  # this parameter will not be tuned in this round\n",
    "}\n",
    "\n",
    "os.environ[\"TUNE_DISABLE_AUTO_CALLBACK_LOGGERS\"] = \"1\"\n",
    "\n",
    "ray.shutdown()\n",
    "ray.init(num_gpus=1, logging_level=logging.ERROR)\n",
    "resources = {\"gpu\": 1}\n",
    "trainable_with_resources = tune.with_resources(tune_enet, resources)\n",
    "\n",
    "start_tune = dt.now().strftime(\"%H-%M-%S\")\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    tune.with_parameters(trainable_with_resources,\n",
    "                         start_time_tuning=start_tune),\n",
    "    tune_config=tune.TuneConfig(\n",
    "        num_samples=20,\n",
    "        scheduler=ASHAScheduler(metric=\"val_ccc\", mode=\"max\")\n",
    "    ),\n",
    "    param_space=search_space\n",
    ")\n",
    "\n",
    "results = tuner.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ed278f-d3bb-4c65-b14d-9afe56673532",
   "metadata": {},
   "source": [
    "Observations\n",
    "* Larger batch sizes yield better performances than smaller batch sizes.\n",
    "* Learning rates below 0.001 yield better performances than higher learning rates.\n",
    "* MSE and MAE yield similar performances, so the MSE is focused in the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ef62d20-cd73-4338-a45b-3c0245524d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-05-27 00:44:44</td></tr>\n",
       "<tr><td>Running for: </td><td>02:02:39.05        </td></tr>\n",
       "<tr><td>Memory:      </td><td>27.2/63.7 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=19<br>Bracket: Iter 64.000: None | Iter 16.000: 0.453052328028408 | Iter 4.000: 0.4459691747345273 | Iter 1.000: 0.4057250061070834<br>Logical resource usage: 0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>status    </th><th>loc            </th><th>aug  </th><th style=\"text-align: right;\">        do</th><th style=\"text-align: right;\">     lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  val_ccc</th><th style=\"text-align: right;\">  val_pcc</th><th style=\"text-align: right;\">  val_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>tune_enet_69e10_00000</td><td>TERMINATED</td><td>127.0.0.1:25948</td><td>False</td><td style=\"text-align: right;\">0.224225  </td><td style=\"text-align: right;\">0.00065</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">       1622.2   </td><td style=\"text-align: right;\"> 0.410174</td><td style=\"text-align: right;\"> 0.474734</td><td style=\"text-align: right;\"> 0.0509481</td></tr>\n",
       "<tr><td>tune_enet_69e10_00001</td><td>TERMINATED</td><td>127.0.0.1:7860 </td><td>False</td><td style=\"text-align: right;\">0.0883411 </td><td style=\"text-align: right;\">0.00095</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        326.474 </td><td style=\"text-align: right;\"> 0.399903</td><td style=\"text-align: right;\"> 0.468529</td><td style=\"text-align: right;\"> 0.0501419</td></tr>\n",
       "<tr><td>tune_enet_69e10_00002</td><td>TERMINATED</td><td>127.0.0.1:22456</td><td>False</td><td style=\"text-align: right;\">0.267191  </td><td style=\"text-align: right;\">0.00045</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         84.5168</td><td style=\"text-align: right;\"> 0.380439</td><td style=\"text-align: right;\"> 0.4804  </td><td style=\"text-align: right;\"> 0.0534174</td></tr>\n",
       "<tr><td>tune_enet_69e10_00003</td><td>TERMINATED</td><td>127.0.0.1:25772</td><td>False</td><td style=\"text-align: right;\">0.498996  </td><td style=\"text-align: right;\">0.0006 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         84.9139</td><td style=\"text-align: right;\"> 0.400056</td><td style=\"text-align: right;\"> 0.485991</td><td style=\"text-align: right;\"> 0.0608402</td></tr>\n",
       "<tr><td>tune_enet_69e10_00004</td><td>TERMINATED</td><td>127.0.0.1:28256</td><td>False</td><td style=\"text-align: right;\">0.300071  </td><td style=\"text-align: right;\">0.0009 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         85.314 </td><td style=\"text-align: right;\"> 0.394811</td><td style=\"text-align: right;\"> 0.492886</td><td style=\"text-align: right;\"> 0.0500898</td></tr>\n",
       "<tr><td>tune_enet_69e10_00005</td><td>TERMINATED</td><td>127.0.0.1:27428</td><td>False</td><td style=\"text-align: right;\">0.0624864 </td><td style=\"text-align: right;\">0.0007 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         85.0934</td><td style=\"text-align: right;\"> 0.399146</td><td style=\"text-align: right;\"> 0.494481</td><td style=\"text-align: right;\"> 0.0507884</td></tr>\n",
       "<tr><td>tune_enet_69e10_00006</td><td>TERMINATED</td><td>127.0.0.1:30592</td><td>False</td><td style=\"text-align: right;\">0.117185  </td><td style=\"text-align: right;\">0.00035</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         84.8116</td><td style=\"text-align: right;\"> 0.367164</td><td style=\"text-align: right;\"> 0.465123</td><td style=\"text-align: right;\"> 0.0549372</td></tr>\n",
       "<tr><td>tune_enet_69e10_00007</td><td>TERMINATED</td><td>127.0.0.1:2644 </td><td>True </td><td style=\"text-align: right;\">0.43187   </td><td style=\"text-align: right;\">0.00095</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">       2397.2   </td><td style=\"text-align: right;\"> 0.43985 </td><td style=\"text-align: right;\"> 0.494635</td><td style=\"text-align: right;\"> 0.0515981</td></tr>\n",
       "<tr><td>tune_enet_69e10_00008</td><td>TERMINATED</td><td>127.0.0.1:29420</td><td>True </td><td style=\"text-align: right;\">0.228223  </td><td style=\"text-align: right;\">0.00055</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        603.402 </td><td style=\"text-align: right;\"> 0.400823</td><td style=\"text-align: right;\"> 0.4651  </td><td style=\"text-align: right;\"> 0.0503155</td></tr>\n",
       "<tr><td>tune_enet_69e10_00009</td><td>TERMINATED</td><td>127.0.0.1:6912 </td><td>False</td><td style=\"text-align: right;\">0.013492  </td><td style=\"text-align: right;\">0.0002 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         84.0438</td><td style=\"text-align: right;\"> 0.329708</td><td style=\"text-align: right;\"> 0.424603</td><td style=\"text-align: right;\"> 0.0587024</td></tr>\n",
       "<tr><td>tune_enet_69e10_00010</td><td>TERMINATED</td><td>127.0.0.1:28536</td><td>True </td><td style=\"text-align: right;\">0.358517  </td><td style=\"text-align: right;\">0.00065</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        603.154 </td><td style=\"text-align: right;\"> 0.440728</td><td style=\"text-align: right;\"> 0.500094</td><td style=\"text-align: right;\"> 0.049875 </td></tr>\n",
       "<tr><td>tune_enet_69e10_00011</td><td>TERMINATED</td><td>127.0.0.1:23252</td><td>True </td><td style=\"text-align: right;\">0.267702  </td><td style=\"text-align: right;\">0.0004 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        153.714 </td><td style=\"text-align: right;\"> 0.401718</td><td style=\"text-align: right;\"> 0.493668</td><td style=\"text-align: right;\"> 0.0518569</td></tr>\n",
       "<tr><td>tune_enet_69e10_00012</td><td>TERMINATED</td><td>127.0.0.1:2140 </td><td>False</td><td style=\"text-align: right;\">0.0546363 </td><td style=\"text-align: right;\">0.001  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         84.0597</td><td style=\"text-align: right;\"> 0.392168</td><td style=\"text-align: right;\"> 0.488017</td><td style=\"text-align: right;\"> 0.0502417</td></tr>\n",
       "<tr><td>tune_enet_69e10_00013</td><td>TERMINATED</td><td>127.0.0.1:28984</td><td>False</td><td style=\"text-align: right;\">0.431478  </td><td style=\"text-align: right;\">0.0006 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         84.3213</td><td style=\"text-align: right;\"> 0.404453</td><td style=\"text-align: right;\"> 0.489477</td><td style=\"text-align: right;\"> 0.0594081</td></tr>\n",
       "<tr><td>tune_enet_69e10_00014</td><td>TERMINATED</td><td>127.0.0.1:3064 </td><td>False</td><td style=\"text-align: right;\">0.486836  </td><td style=\"text-align: right;\">0.0006 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         84.2912</td><td style=\"text-align: right;\"> 0.400908</td><td style=\"text-align: right;\"> 0.488093</td><td style=\"text-align: right;\"> 0.0603534</td></tr>\n",
       "<tr><td>tune_enet_69e10_00015</td><td>TERMINATED</td><td>127.0.0.1:14992</td><td>False</td><td style=\"text-align: right;\">0.463404  </td><td style=\"text-align: right;\">0.0002 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         85.1997</td><td style=\"text-align: right;\"> 0.340816</td><td style=\"text-align: right;\"> 0.419729</td><td style=\"text-align: right;\"> 0.0660206</td></tr>\n",
       "<tr><td>tune_enet_69e10_00016</td><td>TERMINATED</td><td>127.0.0.1:29552</td><td>False</td><td style=\"text-align: right;\">0.193458  </td><td style=\"text-align: right;\">0.0005 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         84.3052</td><td style=\"text-align: right;\"> 0.380136</td><td style=\"text-align: right;\"> 0.483285</td><td style=\"text-align: right;\"> 0.0521935</td></tr>\n",
       "<tr><td>tune_enet_69e10_00017</td><td>TERMINATED</td><td>127.0.0.1:24908</td><td>False</td><td style=\"text-align: right;\">0.0305834 </td><td style=\"text-align: right;\">0.0008 </td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        327.126 </td><td style=\"text-align: right;\"> 0.393096</td><td style=\"text-align: right;\"> 0.464307</td><td style=\"text-align: right;\"> 0.0506728</td></tr>\n",
       "<tr><td>tune_enet_69e10_00018</td><td>TERMINATED</td><td>127.0.0.1:18476</td><td>True </td><td style=\"text-align: right;\">0.00328991</td><td style=\"text-align: right;\">0.0004 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        153.577 </td><td style=\"text-align: right;\"> 0.384204</td><td style=\"text-align: right;\"> 0.484012</td><td style=\"text-align: right;\"> 0.0505785</td></tr>\n",
       "<tr><td>tune_enet_69e10_00019</td><td>TERMINATED</td><td>127.0.0.1:1776 </td><td>True </td><td style=\"text-align: right;\">0.172543  </td><td style=\"text-align: right;\">0.0001 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        153.606 </td><td style=\"text-align: right;\"> 0.315653</td><td style=\"text-align: right;\"> 0.412159</td><td style=\"text-align: right;\"> 0.0597262</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(tune_enet pid=25948)\u001b[0m cuda\n",
      "\u001b[36m(tune_enet pid=25948)\u001b[0m [INFO] Created a new pretrained EfficientNet-B0 model.\n",
      "\u001b[36m(tune_enet pid=25948)\u001b[0m Size of the training set: 19803\n",
      "\u001b[36m(tune_enet pid=25948)\u001b[0m Size of the validation set: 4915\n",
      "\u001b[36m(tune_enet pid=25948)\u001b[0m [INFO] Created SummaryWriter, saving to: C:\\local\\AIProject\\runs\\hp_tuning\\pretrained_enet\\fold_1_start_22-42-05\\2024-05-26_22-42-11...\n",
      "\u001b[36m(tune_enet pid=25948)\u001b[0m Epoch: 1 | train_loss: 0.0614 | train_ccc: 0.5205 | train_pcc: 0.5425 | val_loss: 0.0540 | val_ccc: 0.4019 | val_pcc: 0.4940\n",
      "\u001b[36m(tune_enet pid=25948)\u001b[0m Epoch: 2 | train_loss: 0.0421 | train_ccc: 0.6639 | train_pcc: 0.6872 | val_loss: 0.0529 | val_ccc: 0.4388 | val_pcc: 0.5101\n",
      "\u001b[36m(tune_enet pid=25948)\u001b[0m Epoch: 3 | train_loss: 0.0390 | train_ccc: 0.6949 | train_pcc: 0.7174 | val_loss: 0.0555 | val_ccc: 0.4499 | val_pcc: 0.5143\n",
      "\u001b[36m(tune_enet pid=25948)\u001b[0m Epoch: 4 | train_loss: 0.0363 | train_ccc: 0.7230 | train_pcc: 0.7428 | val_loss: 0.0518 | val_ccc: 0.4477 | val_pcc: 0.5086\n",
      "\u001b[36m(tune_enet pid=25948)\u001b[0m Epoch: 5 | train_loss: 0.0344 | train_ccc: 0.7341 | train_pcc: 0.7539 | val_loss: 0.0503 | val_ccc: 0.4534 | val_pcc: 0.5128\n",
      "\u001b[36m(tune_enet pid=25948)\u001b[0m Epoch: 6 | train_loss: 0.0332 | train_ccc: 0.7457 | train_pcc: 0.7634 | val_loss: 0.0489 | val_ccc: 0.4493 | val_pcc: 0.5070\n",
      "\u001b[36m(tune_enet pid=25948)\u001b[0m Epoch: 7 | train_loss: 0.0335 | train_ccc: 0.7470 | train_pcc: 0.7629 | val_loss: 0.0489 | val_ccc: 0.4390 | val_pcc: 0.4978\n",
      "\u001b[36m(tune_enet pid=25948)\u001b[0m Epoch: 8 | train_loss: 0.0315 | train_ccc: 0.7565 | train_pcc: 0.7749 | val_loss: 0.0500 | val_ccc: 0.4359 | val_pcc: 0.4950\n",
      "\u001b[36m(tune_enet pid=25948)\u001b[0m Epoch: 9 | train_loss: 0.0310 | train_ccc: 0.7647 | train_pcc: 0.7803 | val_loss: 0.0499 | val_ccc: 0.4558 | val_pcc: 0.5095\n",
      "\u001b[36m(tune_enet pid=25948)\u001b[0m Epoch: 10 | train_loss: 0.0310 | train_ccc: 0.7662 | train_pcc: 0.7807 | val_loss: 0.0499 | val_ccc: 0.4264 | val_pcc: 0.4898\n",
      "\u001b[36m(tune_enet pid=25948)\u001b[0m Epoch: 11 | train_loss: 0.0308 | train_ccc: 0.7681 | train_pcc: 0.7848 | val_loss: 0.0496 | val_ccc: 0.4331 | val_pcc: 0.4930\n",
      "\u001b[36m(tune_enet pid=25948)\u001b[0m Epoch: 12 | train_loss: 0.0308 | train_ccc: 0.7668 | train_pcc: 0.7827 | val_loss: 0.0498 | val_ccc: 0.4463 | val_pcc: 0.5019\n",
      "\u001b[36m(tune_enet pid=25948)\u001b[0m Epoch: 13 | train_loss: 0.0313 | train_ccc: 0.7636 | train_pcc: 0.7794 | val_loss: 0.0494 | val_ccc: 0.4235 | val_pcc: 0.4885\n",
      "\u001b[36m(tune_enet pid=25948)\u001b[0m Epoch: 14 | train_loss: 0.0306 | train_ccc: 0.7706 | train_pcc: 0.7851 | val_loss: 0.0581 | val_ccc: 0.3028 | val_pcc: 0.3820\n",
      "\u001b[36m(tune_enet pid=25948)\u001b[0m Epoch: 15 | train_loss: 0.0302 | train_ccc: 0.7740 | train_pcc: 0.7875 | val_loss: 0.0502 | val_ccc: 0.4419 | val_pcc: 0.4973\n",
      "\u001b[36m(tune_enet pid=25948)\u001b[0m Epoch: 16 | train_loss: 0.0313 | train_ccc: 0.7688 | train_pcc: 0.7834 | val_loss: 0.0508 | val_ccc: 0.4575 | val_pcc: 0.5110\n",
      "\u001b[36m(tune_enet pid=25948)\u001b[0m Epoch: 17 | train_loss: 0.0310 | train_ccc: 0.7728 | train_pcc: 0.7845 | val_loss: 0.0497 | val_ccc: 0.4228 | val_pcc: 0.4844\n",
      "\u001b[36m(tune_enet pid=25948)\u001b[0m Epoch: 18 | train_loss: 0.0296 | train_ccc: 0.7772 | train_pcc: 0.7930 | val_loss: 0.0502 | val_ccc: 0.4151 | val_pcc: 0.4780\n",
      "\u001b[36m(tune_enet pid=25948)\u001b[0m Epoch: 19 | train_loss: 0.0297 | train_ccc: 0.7787 | train_pcc: 0.7920 | val_loss: 0.0520 | val_ccc: 0.4416 | val_pcc: 0.4962\n",
      "\u001b[36m(tune_enet pid=25948)\u001b[0m Epoch: 20 | train_loss: 0.0304 | train_ccc: 0.7762 | train_pcc: 0.7890 | val_loss: 0.0509 | val_ccc: 0.4102 | val_pcc: 0.4747\n",
      "\u001b[36m(tune_enet pid=7860)\u001b[0m cuda\n",
      "\u001b[36m(tune_enet pid=7860)\u001b[0m [INFO] Created a new pretrained EfficientNet-B0 model.\n",
      "\u001b[36m(tune_enet pid=7860)\u001b[0m Size of the training set: 19803\n",
      "\u001b[36m(tune_enet pid=7860)\u001b[0m Size of the validation set: 4915\n",
      "\u001b[36m(tune_enet pid=7860)\u001b[0m [INFO] Created SummaryWriter, saving to: C:\\local\\AIProject\\runs\\hp_tuning\\pretrained_enet\\fold_1_start_22-42-05\\2024-05-26_23-09-17...\n",
      "\u001b[36m(tune_enet pid=7860)\u001b[0m Epoch: 1 | train_loss: 0.0530 | train_ccc: 0.5722 | train_pcc: 0.6032 | val_loss: 0.0512 | val_ccc: 0.4172 | val_pcc: 0.5006\n",
      "\u001b[36m(tune_enet pid=7860)\u001b[0m Epoch: 2 | train_loss: 0.0360 | train_ccc: 0.7126 | train_pcc: 0.7408 | val_loss: 0.0514 | val_ccc: 0.3734 | val_pcc: 0.4553\n",
      "\u001b[36m(tune_enet pid=7860)\u001b[0m Epoch: 3 | train_loss: 0.0323 | train_ccc: 0.7451 | train_pcc: 0.7703 | val_loss: 0.0506 | val_ccc: 0.3920 | val_pcc: 0.4612\n",
      "\u001b[36m(tune_enet pid=7860)\u001b[0m Epoch: 4 | train_loss: 0.0308 | train_ccc: 0.7621 | train_pcc: 0.7834 | val_loss: 0.0501 | val_ccc: 0.3999 | val_pcc: 0.4685\n",
      "\u001b[36m(tune_enet pid=22456)\u001b[0m cuda\n",
      "\u001b[36m(tune_enet pid=22456)\u001b[0m [INFO] Created a new pretrained EfficientNet-B0 model.\n",
      "\u001b[36m(tune_enet pid=22456)\u001b[0m Size of the training set: 19803\n",
      "\u001b[36m(tune_enet pid=22456)\u001b[0m Size of the validation set: 4915\n",
      "\u001b[36m(tune_enet pid=22456)\u001b[0m [INFO] Created SummaryWriter, saving to: C:\\local\\AIProject\\runs\\hp_tuning\\pretrained_enet\\fold_1_start_22-42-05\\2024-05-26_23-14-49...\n",
      "\u001b[36m(tune_enet pid=22456)\u001b[0m Epoch: 1 | train_loss: 0.0637 | train_ccc: 0.4834 | train_pcc: 0.5056 | val_loss: 0.0534 | val_ccc: 0.3804 | val_pcc: 0.4804\n",
      "\u001b[36m(tune_enet pid=25772)\u001b[0m cuda\n",
      "\u001b[36m(tune_enet pid=25772)\u001b[0m [INFO] Created a new pretrained EfficientNet-B0 model.\n",
      "\u001b[36m(tune_enet pid=25772)\u001b[0m Size of the training set: 19803\n",
      "\u001b[36m(tune_enet pid=25772)\u001b[0m Size of the validation set: 4915\n",
      "\u001b[36m(tune_enet pid=25772)\u001b[0m [INFO] Created SummaryWriter, saving to: C:\\local\\AIProject\\runs\\hp_tuning\\pretrained_enet\\fold_1_start_22-42-05\\2024-05-26_23-16-18...\n",
      "\u001b[36m(tune_enet pid=25772)\u001b[0m Epoch: 1 | train_loss: 0.0680 | train_ccc: 0.4962 | train_pcc: 0.5073 | val_loss: 0.0608 | val_ccc: 0.4001 | val_pcc: 0.4860\n",
      "\u001b[36m(tune_enet pid=28256)\u001b[0m cuda\n",
      "\u001b[36m(tune_enet pid=28256)\u001b[0m [INFO] Created a new pretrained EfficientNet-B0 model.\n",
      "\u001b[36m(tune_enet pid=28256)\u001b[0m Size of the training set: 19803\n",
      "\u001b[36m(tune_enet pid=28256)\u001b[0m Size of the validation set: 4915\n",
      "\u001b[36m(tune_enet pid=28256)\u001b[0m [INFO] Created SummaryWriter, saving to: C:\\local\\AIProject\\runs\\hp_tuning\\pretrained_enet\\fold_1_start_22-42-05\\2024-05-26_23-17-47...\n",
      "\u001b[36m(tune_enet pid=28256)\u001b[0m Epoch: 1 | train_loss: 0.0575 | train_ccc: 0.5527 | train_pcc: 0.5721 | val_loss: 0.0501 | val_ccc: 0.3948 | val_pcc: 0.4929\n",
      "\u001b[36m(tune_enet pid=27428)\u001b[0m cuda\n",
      "\u001b[36m(tune_enet pid=27428)\u001b[0m [INFO] Created a new pretrained EfficientNet-B0 model.\n",
      "\u001b[36m(tune_enet pid=27428)\u001b[0m Size of the training set: 19803\n",
      "\u001b[36m(tune_enet pid=27428)\u001b[0m Size of the validation set: 4915\n",
      "\u001b[36m(tune_enet pid=27428)\u001b[0m [INFO] Created SummaryWriter, saving to: C:\\local\\AIProject\\runs\\hp_tuning\\pretrained_enet\\fold_1_start_22-42-05\\2024-05-26_23-19-17...\n",
      "\u001b[36m(tune_enet pid=27428)\u001b[0m Epoch: 1 | train_loss: 0.0558 | train_ccc: 0.5413 | train_pcc: 0.5767 | val_loss: 0.0508 | val_ccc: 0.3991 | val_pcc: 0.4945\n",
      "\u001b[36m(tune_enet pid=30592)\u001b[0m cuda\n",
      "\u001b[36m(tune_enet pid=30592)\u001b[0m [INFO] Created a new pretrained EfficientNet-B0 model.\n",
      "\u001b[36m(tune_enet pid=30592)\u001b[0m Size of the training set: 19803\n",
      "\u001b[36m(tune_enet pid=30592)\u001b[0m Size of the validation set: 4915\n",
      "\u001b[36m(tune_enet pid=30592)\u001b[0m [INFO] Created SummaryWriter, saving to: C:\\local\\AIProject\\runs\\hp_tuning\\pretrained_enet\\fold_1_start_22-42-05\\2024-05-26_23-20-47...\n",
      "\u001b[36m(tune_enet pid=30592)\u001b[0m Epoch: 1 | train_loss: 0.0623 | train_ccc: 0.4619 | train_pcc: 0.4968 | val_loss: 0.0549 | val_ccc: 0.3672 | val_pcc: 0.4651\n",
      "\u001b[36m(tune_enet pid=2644)\u001b[0m cuda\n",
      "\u001b[36m(tune_enet pid=2644)\u001b[0m [INFO] Created a new pretrained EfficientNet-B0 model.\n",
      "\u001b[36m(tune_enet pid=2644)\u001b[0m Size of the training set: 39606\n",
      "\u001b[36m(tune_enet pid=2644)\u001b[0m Size of the validation set: 4915\n",
      "\u001b[36m(tune_enet pid=2644)\u001b[0m [INFO] Created SummaryWriter, saving to: C:\\local\\AIProject\\runs\\hp_tuning\\pretrained_enet\\fold_1_start_22-42-05\\2024-05-26_23-22-16...\n",
      "\u001b[36m(tune_enet pid=2644)\u001b[0m Epoch: 1 | train_loss: 0.0542 | train_ccc: 0.5998 | train_pcc: 0.6130 | val_loss: 0.0575 | val_ccc: 0.4352 | val_pcc: 0.5012\n",
      "\u001b[36m(tune_enet pid=2644)\u001b[0m Epoch: 2 | train_loss: 0.0424 | train_ccc: 0.6916 | train_pcc: 0.7032 | val_loss: 0.0522 | val_ccc: 0.4330 | val_pcc: 0.4952\n",
      "\u001b[36m(tune_enet pid=2644)\u001b[0m Epoch: 3 | train_loss: 0.0395 | train_ccc: 0.7095 | train_pcc: 0.7238 | val_loss: 0.0505 | val_ccc: 0.4094 | val_pcc: 0.4794\n",
      "\u001b[36m(tune_enet pid=2644)\u001b[0m Epoch: 4 | train_loss: 0.0387 | train_ccc: 0.7149 | train_pcc: 0.7287 | val_loss: 0.0495 | val_ccc: 0.4508 | val_pcc: 0.5125\n",
      "\u001b[36m(tune_enet pid=2644)\u001b[0m Epoch: 5 | train_loss: 0.0380 | train_ccc: 0.7203 | train_pcc: 0.7329 | val_loss: 0.0510 | val_ccc: 0.4341 | val_pcc: 0.4984\n",
      "\u001b[36m(tune_enet pid=2644)\u001b[0m Epoch: 6 | train_loss: 0.0377 | train_ccc: 0.7199 | train_pcc: 0.7341 | val_loss: 0.0511 | val_ccc: 0.4316 | val_pcc: 0.4886\n",
      "\u001b[36m(tune_enet pid=2644)\u001b[0m Epoch: 7 | train_loss: 0.0381 | train_ccc: 0.7195 | train_pcc: 0.7330 | val_loss: 0.0513 | val_ccc: 0.4179 | val_pcc: 0.4883\n",
      "\u001b[36m(tune_enet pid=2644)\u001b[0m Epoch: 8 | train_loss: 0.0377 | train_ccc: 0.7206 | train_pcc: 0.7347 | val_loss: 0.0523 | val_ccc: 0.4313 | val_pcc: 0.4913\n",
      "\u001b[36m(tune_enet pid=2644)\u001b[0m Epoch: 9 | train_loss: 0.0371 | train_ccc: 0.7213 | train_pcc: 0.7358 | val_loss: 0.0509 | val_ccc: 0.4047 | val_pcc: 0.4731\n",
      "\u001b[36m(tune_enet pid=2644)\u001b[0m Epoch: 10 | train_loss: 0.0368 | train_ccc: 0.7232 | train_pcc: 0.7381 | val_loss: 0.0510 | val_ccc: 0.4243 | val_pcc: 0.4923\n",
      "\u001b[36m(tune_enet pid=2644)\u001b[0m Epoch: 11 | train_loss: 0.0372 | train_ccc: 0.7207 | train_pcc: 0.7353 | val_loss: 0.0526 | val_ccc: 0.4365 | val_pcc: 0.5002\n",
      "\u001b[36m(tune_enet pid=2644)\u001b[0m Epoch: 12 | train_loss: 0.0380 | train_ccc: 0.7188 | train_pcc: 0.7332 | val_loss: 0.0505 | val_ccc: 0.4122 | val_pcc: 0.4798\n",
      "\u001b[36m(tune_enet pid=2644)\u001b[0m Epoch: 13 | train_loss: 0.0379 | train_ccc: 0.7181 | train_pcc: 0.7327 | val_loss: 0.0520 | val_ccc: 0.4328 | val_pcc: 0.4967\n",
      "\u001b[36m(tune_enet pid=2644)\u001b[0m Epoch: 14 | train_loss: 0.0377 | train_ccc: 0.7198 | train_pcc: 0.7338 | val_loss: 0.0515 | val_ccc: 0.4353 | val_pcc: 0.4982\n",
      "\u001b[36m(tune_enet pid=2644)\u001b[0m Epoch: 15 | train_loss: 0.0370 | train_ccc: 0.7221 | train_pcc: 0.7370 | val_loss: 0.0498 | val_ccc: 0.3854 | val_pcc: 0.4624\n",
      "\u001b[36m(tune_enet pid=2644)\u001b[0m Epoch: 16 | train_loss: 0.0365 | train_ccc: 0.7249 | train_pcc: 0.7401 | val_loss: 0.0516 | val_ccc: 0.4399 | val_pcc: 0.4946\n",
      "\u001b[36m(tune_enet pid=29420)\u001b[0m cuda\n",
      "\u001b[36m(tune_enet pid=29420)\u001b[0m [INFO] Created a new pretrained EfficientNet-B0 model.\n",
      "\u001b[36m(tune_enet pid=29420)\u001b[0m Size of the training set: 39606\n",
      "\u001b[36m(tune_enet pid=29420)\u001b[0m Size of the validation set: 4915\n",
      "\u001b[36m(tune_enet pid=29420)\u001b[0m [INFO] Created SummaryWriter, saving to: C:\\local\\AIProject\\runs\\hp_tuning\\pretrained_enet\\fold_1_start_22-42-05\\2024-05-27_00-02-18...\n",
      "\u001b[36m(tune_enet pid=29420)\u001b[0m Epoch: 1 | train_loss: 0.0533 | train_ccc: 0.5709 | train_pcc: 0.5974 | val_loss: 0.0525 | val_ccc: 0.4201 | val_pcc: 0.5011\n",
      "\u001b[36m(tune_enet pid=29420)\u001b[0m Epoch: 2 | train_loss: 0.0386 | train_ccc: 0.6979 | train_pcc: 0.7190 | val_loss: 0.0496 | val_ccc: 0.3959 | val_pcc: 0.4747\n",
      "\u001b[36m(tune_enet pid=29420)\u001b[0m Epoch: 3 | train_loss: 0.0352 | train_ccc: 0.7284 | train_pcc: 0.7479 | val_loss: 0.0502 | val_ccc: 0.4434 | val_pcc: 0.5033\n",
      "\u001b[36m(tune_enet pid=29420)\u001b[0m Epoch: 4 | train_loss: 0.0332 | train_ccc: 0.7456 | train_pcc: 0.7632 | val_loss: 0.0503 | val_ccc: 0.4008 | val_pcc: 0.4651\n",
      "\u001b[36m(tune_enet pid=6912)\u001b[0m cuda\n",
      "\u001b[36m(tune_enet pid=6912)\u001b[0m [INFO] Created a new pretrained EfficientNet-B0 model.\n",
      "\u001b[36m(tune_enet pid=6912)\u001b[0m Size of the training set: 19803\n",
      "\u001b[36m(tune_enet pid=6912)\u001b[0m Size of the validation set: 4915\n",
      "\u001b[36m(tune_enet pid=6912)\u001b[0m [INFO] Created SummaryWriter, saving to: C:\\local\\AIProject\\runs\\hp_tuning\\pretrained_enet\\fold_1_start_22-42-05\\2024-05-27_00-12-25...\n",
      "\u001b[36m(tune_enet pid=6912)\u001b[0m Epoch: 1 | train_loss: 0.0669 | train_ccc: 0.3899 | train_pcc: 0.4405 | val_loss: 0.0587 | val_ccc: 0.3297 | val_pcc: 0.4246\n",
      "\u001b[36m(tune_enet pid=28536)\u001b[0m cuda\n",
      "\u001b[36m(tune_enet pid=28536)\u001b[0m [INFO] Created a new pretrained EfficientNet-B0 model.\n",
      "\u001b[36m(tune_enet pid=28536)\u001b[0m Size of the training set: 39606\n",
      "\u001b[36m(tune_enet pid=28536)\u001b[0m Size of the validation set: 4915\n",
      "\u001b[36m(tune_enet pid=28536)\u001b[0m [INFO] Created SummaryWriter, saving to: C:\\local\\AIProject\\runs\\hp_tuning\\pretrained_enet\\fold_1_start_22-42-05\\2024-05-27_00-13-54...\n",
      "\u001b[36m(tune_enet pid=28536)\u001b[0m Epoch: 1 | train_loss: 0.0557 | train_ccc: 0.5735 | train_pcc: 0.5910 | val_loss: 0.0539 | val_ccc: 0.4168 | val_pcc: 0.4957\n",
      "\u001b[36m(tune_enet pid=28536)\u001b[0m Epoch: 2 | train_loss: 0.0413 | train_ccc: 0.6899 | train_pcc: 0.7051 | val_loss: 0.0500 | val_ccc: 0.3883 | val_pcc: 0.4734\n",
      "\u001b[36m(tune_enet pid=28536)\u001b[0m Epoch: 3 | train_loss: 0.0379 | train_ccc: 0.7133 | train_pcc: 0.7295 | val_loss: 0.0505 | val_ccc: 0.4369 | val_pcc: 0.4992\n",
      "\u001b[36m(tune_enet pid=28536)\u001b[0m Epoch: 4 | train_loss: 0.0359 | train_ccc: 0.7282 | train_pcc: 0.7437 | val_loss: 0.0499 | val_ccc: 0.4407 | val_pcc: 0.5001\n",
      "\u001b[36m(tune_enet pid=23252)\u001b[0m cuda\n",
      "\u001b[36m(tune_enet pid=23252)\u001b[0m [INFO] Created a new pretrained EfficientNet-B0 model.\n",
      "\u001b[36m(tune_enet pid=23252)\u001b[0m Size of the training set: 39606\n",
      "\u001b[36m(tune_enet pid=23252)\u001b[0m Size of the validation set: 4915\n",
      "\u001b[36m(tune_enet pid=23252)\u001b[0m [INFO] Created SummaryWriter, saving to: C:\\local\\AIProject\\runs\\hp_tuning\\pretrained_enet\\fold_1_start_22-42-05\\2024-05-27_00-24-01...\n",
      "\u001b[36m(tune_enet pid=23252)\u001b[0m Epoch: 1 | train_loss: 0.0564 | train_ccc: 0.5440 | train_pcc: 0.5695 | val_loss: 0.0519 | val_ccc: 0.4017 | val_pcc: 0.4937\n",
      "\u001b[36m(tune_enet pid=2140)\u001b[0m cuda\n",
      "\u001b[36m(tune_enet pid=2140)\u001b[0m [INFO] Created a new pretrained EfficientNet-B0 model.\n",
      "\u001b[36m(tune_enet pid=2140)\u001b[0m Size of the training set: 19803\n",
      "\u001b[36m(tune_enet pid=2140)\u001b[0m Size of the validation set: 4915\n",
      "\u001b[36m(tune_enet pid=2140)\u001b[0m [INFO] Created SummaryWriter, saving to: C:\\local\\AIProject\\runs\\hp_tuning\\pretrained_enet\\fold_1_start_22-42-05\\2024-05-27_00-26-38...\n",
      "\u001b[36m(tune_enet pid=2140)\u001b[0m Epoch: 1 | train_loss: 0.0531 | train_ccc: 0.5747 | train_pcc: 0.6053 | val_loss: 0.0502 | val_ccc: 0.3922 | val_pcc: 0.4880\n",
      "\u001b[36m(tune_enet pid=28984)\u001b[0m cuda\n",
      "\u001b[36m(tune_enet pid=28984)\u001b[0m [INFO] Created a new pretrained EfficientNet-B0 model.\n",
      "\u001b[36m(tune_enet pid=28984)\u001b[0m Size of the training set: 19803\n",
      "\u001b[36m(tune_enet pid=28984)\u001b[0m Size of the validation set: 4915\n",
      "\u001b[36m(tune_enet pid=28984)\u001b[0m [INFO] Created SummaryWriter, saving to: C:\\local\\AIProject\\runs\\hp_tuning\\pretrained_enet\\fold_1_start_22-42-05\\2024-05-27_00-28-07...\n",
      "\u001b[36m(tune_enet pid=28984)\u001b[0m Epoch: 1 | train_loss: 0.0653 | train_ccc: 0.5057 | train_pcc: 0.5206 | val_loss: 0.0594 | val_ccc: 0.4045 | val_pcc: 0.4895\n",
      "\u001b[36m(tune_enet pid=3064)\u001b[0m cuda\n",
      "\u001b[36m(tune_enet pid=3064)\u001b[0m [INFO] Created a new pretrained EfficientNet-B0 model.\n",
      "\u001b[36m(tune_enet pid=3064)\u001b[0m Size of the training set: 19803\n",
      "\u001b[36m(tune_enet pid=3064)\u001b[0m Size of the validation set: 4915\n",
      "\u001b[36m(tune_enet pid=3064)\u001b[0m [INFO] Created SummaryWriter, saving to: C:\\local\\AIProject\\runs\\hp_tuning\\pretrained_enet\\fold_1_start_22-42-05\\2024-05-27_00-29-36...\n",
      "\u001b[36m(tune_enet pid=3064)\u001b[0m Epoch: 1 | train_loss: 0.0672 | train_ccc: 0.4973 | train_pcc: 0.5094 | val_loss: 0.0604 | val_ccc: 0.4009 | val_pcc: 0.4881\n",
      "\u001b[36m(tune_enet pid=14992)\u001b[0m cuda\n",
      "\u001b[36m(tune_enet pid=14992)\u001b[0m [INFO] Created a new pretrained EfficientNet-B0 model.\n",
      "\u001b[36m(tune_enet pid=14992)\u001b[0m Size of the training set: 19803\n",
      "\u001b[36m(tune_enet pid=14992)\u001b[0m Size of the validation set: 4915\n",
      "\u001b[36m(tune_enet pid=14992)\u001b[0m [INFO] Created SummaryWriter, saving to: C:\\local\\AIProject\\runs\\hp_tuning\\pretrained_enet\\fold_1_start_22-42-05\\2024-05-27_00-31-05...\n",
      "\u001b[36m(tune_enet pid=14992)\u001b[0m Epoch: 1 | train_loss: 0.0765 | train_ccc: 0.3811 | train_pcc: 0.3960 | val_loss: 0.0660 | val_ccc: 0.3408 | val_pcc: 0.4197\n",
      "\u001b[36m(tune_enet pid=29552)\u001b[0m cuda\n",
      "\u001b[36m(tune_enet pid=29552)\u001b[0m [INFO] Created a new pretrained EfficientNet-B0 model.\n",
      "\u001b[36m(tune_enet pid=29552)\u001b[0m Size of the training set: 19803\n",
      "\u001b[36m(tune_enet pid=29552)\u001b[0m Size of the validation set: 4915\n",
      "\u001b[36m(tune_enet pid=29552)\u001b[0m [INFO] Created SummaryWriter, saving to: C:\\local\\AIProject\\runs\\hp_tuning\\pretrained_enet\\fold_1_start_22-42-05\\2024-05-27_00-32-34...\n",
      "\u001b[36m(tune_enet pid=29552)\u001b[0m Epoch: 1 | train_loss: 0.0612 | train_ccc: 0.4970 | train_pcc: 0.5239 | val_loss: 0.0522 | val_ccc: 0.3801 | val_pcc: 0.4833\n",
      "\u001b[36m(tune_enet pid=24908)\u001b[0m cuda\n",
      "\u001b[36m(tune_enet pid=24908)\u001b[0m [INFO] Created a new pretrained EfficientNet-B0 model.\n",
      "\u001b[36m(tune_enet pid=24908)\u001b[0m Size of the training set: 19803\n",
      "\u001b[36m(tune_enet pid=24908)\u001b[0m Size of the validation set: 4915\n",
      "\u001b[36m(tune_enet pid=24908)\u001b[0m [INFO] Created SummaryWriter, saving to: C:\\local\\AIProject\\runs\\hp_tuning\\pretrained_enet\\fold_1_start_22-42-05\\2024-05-27_00-34-03...\n",
      "\u001b[36m(tune_enet pid=24908)\u001b[0m Epoch: 1 | train_loss: 0.0528 | train_ccc: 0.5582 | train_pcc: 0.5979 | val_loss: 0.0507 | val_ccc: 0.4095 | val_pcc: 0.4988\n",
      "\u001b[36m(tune_enet pid=24908)\u001b[0m Epoch: 2 | train_loss: 0.0348 | train_ccc: 0.7099 | train_pcc: 0.7474 | val_loss: 0.0504 | val_ccc: 0.3937 | val_pcc: 0.4753\n",
      "\u001b[36m(tune_enet pid=24908)\u001b[0m Epoch: 3 | train_loss: 0.0316 | train_ccc: 0.7416 | train_pcc: 0.7748 | val_loss: 0.0492 | val_ccc: 0.4257 | val_pcc: 0.4911\n",
      "\u001b[36m(tune_enet pid=24908)\u001b[0m Epoch: 4 | train_loss: 0.0295 | train_ccc: 0.7653 | train_pcc: 0.7933 | val_loss: 0.0507 | val_ccc: 0.3931 | val_pcc: 0.4643\n",
      "\u001b[36m(tune_enet pid=18476)\u001b[0m cuda\n",
      "\u001b[36m(tune_enet pid=18476)\u001b[0m [INFO] Created a new pretrained EfficientNet-B0 model.\n",
      "\u001b[36m(tune_enet pid=18476)\u001b[0m Size of the training set: 39606\n",
      "\u001b[36m(tune_enet pid=18476)\u001b[0m Size of the validation set: 4915\n",
      "\u001b[36m(tune_enet pid=18476)\u001b[0m [INFO] Created SummaryWriter, saving to: C:\\local\\AIProject\\runs\\hp_tuning\\pretrained_enet\\fold_1_start_22-42-05\\2024-05-27_00-39-35...\n",
      "\u001b[36m(tune_enet pid=18476)\u001b[0m Epoch: 1 | train_loss: 0.0502 | train_ccc: 0.5587 | train_pcc: 0.6132 | val_loss: 0.0506 | val_ccc: 0.3842 | val_pcc: 0.4840\n",
      "\u001b[36m(tune_enet pid=1776)\u001b[0m cuda\n",
      "\u001b[36m(tune_enet pid=1776)\u001b[0m [INFO] Created a new pretrained EfficientNet-B0 model.\n",
      "\u001b[36m(tune_enet pid=1776)\u001b[0m Size of the training set: 39606\n",
      "\u001b[36m(tune_enet pid=1776)\u001b[0m Size of the validation set: 4915\n",
      "\u001b[36m(tune_enet pid=1776)\u001b[0m [INFO] Created SummaryWriter, saving to: C:\\local\\AIProject\\runs\\hp_tuning\\pretrained_enet\\fold_1_start_22-42-05\\2024-05-27_00-42-13...\n",
      "\u001b[36m(tune_enet pid=1776)\u001b[0m Epoch: 1 | train_loss: 0.0694 | train_ccc: 0.3639 | train_pcc: 0.4052 | val_loss: 0.0597 | val_ccc: 0.3157 | val_pcc: 0.4122\n"
     ]
    }
   ],
   "source": [
    "# second hyperparameter tuning run\n",
    "search_space = {\n",
    "    \"bs\": 256,\n",
    "    \"do\": tune.uniform(0.0, 0.5),\n",
    "    \"loss_fn\": \"MSE\",\n",
    "    \"lr\": tune.quniform(1e-4, 1e-3, 5e-5),\n",
    "    \"aug\": tune.choice([True, False])  \n",
    "}\n",
    "\n",
    "os.environ[\"TUNE_DISABLE_AUTO_CALLBACK_LOGGERS\"] = \"1\"\n",
    "\n",
    "ray.shutdown()\n",
    "ray.init(num_gpus=1, logging_level=logging.ERROR)\n",
    "resources = {\"gpu\": 1}\n",
    "trainable_with_resources = tune.with_resources(tune_enet, resources)\n",
    "\n",
    "start_tune = dt.now().strftime(\"%H-%M-%S\")\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    tune.with_parameters(trainable_with_resources,\n",
    "                         start_time_tuning=start_tune),\n",
    "    tune_config=tune.TuneConfig(\n",
    "        num_samples=20,\n",
    "        scheduler=ASHAScheduler(metric=\"val_ccc\", mode=\"max\")\n",
    "    ),\n",
    "    param_space=search_space\n",
    ")\n",
    "\n",
    "results = tuner.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad5b9f0-de45-4f98-8bbb-6cc8302ea6de",
   "metadata": {},
   "source": [
    "Observations\n",
    "* All tested hyperparameter combinations achieve similar performance.\n",
    "* This will be validated in the next step using cross validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e1a049-e570-44e3-a491-f92233ffd76c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
